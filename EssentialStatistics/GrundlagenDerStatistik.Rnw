\documentclass[a4paper,twoside]{tufte-book} %style file is in the same folder.

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{german}

\usepackage{color}
\usepackage{xcolor}
\usepackage{framed}
\usepackage{listings}

\usepackage{graphicx}

\usepackage{multicol}              
\usepackage{multirow}
\usepackage{booktabs}
%\usepackage{natbib} 

\usepackage[innerrightmargin = 0.7cm, innerleftmargin = 0.3cm]{mdframed}
\usepackage{mdwlist}

\usepackage[]{hyperref}
\definecolor{darkblue}{rgb}{0,0,.5}
\hypersetup{colorlinks=true, breaklinks=true, linkcolor=darkblue, menucolor=darkblue, urlcolor=blue, citecolor=darkblue}

\usepackage[toc,page]{appendix}


\setcounter{secnumdepth}{1}
\setcounter{tocdepth}{1}

\lstset{ % settings for listings needs to be be changed to R sytanx 
language=R,
breaklines = true,
columns=fullflexible,
breakautoindent = false,
%basicstyle=\listingsfont, 
basicstyle=\ttfamily \scriptsize,
keywordstyle=\color{black},                          
identifierstyle=\color{black},
commentstyle=\color{gray},
xleftmargin=3.4pt,
xrightmargin=3.4pt,
numbers=none,
literate={*}{{\char42}}1
         {-}{{\char45}}1
         {\ }{{\copyablespace}}1
}
% http://www.monperrus.net/martin/copy-pastable-listings-in-pdf-from-latex
\usepackage[space=true]{accsupp}
% requires the latest version of package accsupp
\newcommand{\copyablespace}{
    \BeginAccSupp{method=hex,unicode,ActualText=00A0}
\ %
    \EndAccSupp{}
}



<<setup, cache=FALSE, include=FALSE>>=
library(knitr)
opts_knit$set(tidy = T, fig=TRUE, fig.height = 4, fig.width=4, fig.align='center')
render_listings()
@

<<echo=F, results='hide'>>=
set.seed(123)
@



\title{Essentielle\\Statistik}
\author{Florian Hartig}


\begin{document}
%\SweaveOpts{concordance=TRUE}
%\SweaveOpts{concordance=TRUE} % don't activate this for knitr

\let\cleardoublepage\clearpage % No empty pages between chapters
\maketitle


\thispagestyle{empty}
\null

\begin{fullwidth}
Diese Vorlesung ist empfehlenswert f?r Studenten der

\begin{itemize*}
  \item BSc Biostatistik
  \item MSc Research Skills (Webseite \href{http://florianhartig.github.io/ResearchSkills/}{hier})
\end{itemize*}

\vspace{0.5cm}

Anmerkungen / Fragen an:\\[0.5cm]
\href{https://florianhartig.wordpress.com/}{Florian Hartig}\\
Universit?t Regensburg\\
Germany\\[0.5cm]

Probleme oder Unklarheiten bei dieser Vorlesung k?nnen mittels \href{https://github.com/florianhartig/Statistics/issues}{issue tracker} der \href{https://github.com/florianhartig/Statistics/tree/master/EssentialStatistics}{GitHub repository} gemeldet werden. 

\end{fullwidth}


\vfill
\begin{fullwidth}
Erstellt 2014. Updated 2015. Diese Arbeit f?llt unter die 'Creative Commons Attribution-NonCommercial- NoDerivatives 4.0 International' Lizenz.
\end{fullwidth}


\newpage
\tableofcontents

\chapter{Einleitung} % Use chapters instead of sections

	\section{Absichten und vorgesehene Zielgruppe}
	
	Dieses Dokument beinhaltet eine kurze EinfÃ¼hrung in die Statistik und in statistische Analysen, welche in elementaren Experimenten und beobachteten Situationen h?ufig von N?ten sind~\ref{sec: further readings}.
	
	\section{Themen der Statistik und Datenwissenschaften}
	Statistik, oder auch Datenwissenschaften, behandelt die Visualisierung, Zusammenfassung und Interpretation von Daten. Dieses Skript beinhaltet eine Einf?hrung an die vier wichtigsten S?ulen der statistischen Methodik f?r einen quantitativen Wissenschaftler:
	
	\paragraph{Deskriptive Statistik:} Deskriptive Statistik\marginnote{Deskriptive Statistik = Plots, Ma?zahlen der Statistik} beinhaltet die Ma?zahlen der Statistik, wie beispielsweise der Mittel- oder Medianwert, aber auch weitere Optionen, um Daten zu visualisieren.
	
	\paragraph{Inferenzstatistik:} Inferenzstatistik\marginnote{Inferenzstatistik = Parametersch?tzungen, p-Werte, Tests} behandelt das Testen von Hypothesen und Sch?tzen von Parametern. Inferenz basiert typischerweise auf Annahmen, welche in einem statistischen Modell zusammengefasst sind.\marginnote{Ein statistisches Modell beschreibt, wie Daten erstellt werden = Datenerzeugender Prozess} Ein statistisches Modell wird auch als "`Datenerzeugender Prozess"' bezeichnet, da es Annahmen ?ber einen Prozess beschreibt, die zu einer Variation an Daten f?hrt (systematisch und stochastisch).
	
	\paragraph{Vorhersagende Statistik und maschinelles Lernen:} Vorhersagende Statistik und maschinelles Lernen\marginnote{Maschinelles Lernen = Vorhersagende Modelle. Gro?e Dateien = umfangreiche Datens?tze, z.\,B. von Amazon-Endkunden} arbeiten mit herleitenden Vorhersagen aus v.\,A. sehr "`gro?en Dateien"'. Der Hauptunterschied zur Inferenzstatistik ist, dass der Fokus auf der entstehenden Methode liegt, um gute Vorhersagen treffen zu k?nnen ohne ein vorhergehendes Beschreiben, Folgern oder Testen von Annahmen ?ber den Datenerzeugenden Prozess.
	
	\paragraph{Experimentelle Planung:} Experimentelle Planung\marginnote{Experimentelle Planung oder Analysenplanung = das Erhalten und Erzeugen von Daten} umfasst alle Aspekte der Datenerzeugung, insbesondere Fragen wie "`Welche Variablen sollten erfasst werden?"', "`Wie viele Replikate werden ben?tigt?"', "`Wie sollten die Variablen in einem Experiment optimalerweise ver?ndert werden?"'
	
	
	\section{Die Umgebung R f?r statistische Berechnungen}
	
	Die Zeiten als Statistik noch mit Stift, Papier und Taschenrechner durchgef?hrt wurde sind nun mehr oder weniger vorbei. Heutzutage werden statistische Analysen am Computer durchgef?hrt, wof?r es eine Reihe von Software-Umgebungen gibt.
	
	In diesem Skript werden alle Beispiele mit Hilfe von R berechnet werden; wobei der Fokus jedoch nicht auf einer Einf?hrung in R an sich liegen wird. Bei Bedarf f?hrt  \href{http://biometry.github.io/APES/R/R10-gettingStarted.html}{dieser Link} zu einer Einf?hrung, inklusive Hilfestellungen f?r die Installation der Software.
	
	\begin{figure}[]
		\begin{center}
			\includegraphics[width = 10cm]{rst_interface.png}
			\caption{Der RStudio Editor ist der wohl beliebteste Editor f?r R. R ist eine Script-basierende Sprache. Hier kommuniziert man nicht durch Klicken mit dem Computer, sondern gibt Anweisungen anhand von direkten Befehlen in die R Konsole, oder durch das vorhergehende Anlegen eines Text-Dokuments, welches dann die Befehle auswertet. Wenn man diese Herangehensweise nicht gew?hnt ist, kann es eine Weile dauern, bis man damit warm wird. Wenn man sich jedoch damit angefreundet hat, wird man bald merken, wie komfortabel und vorteilhaft es ist, alle Schritte der Analyse in einem Textdokument aufgelistet wiederzufinden und somit alles zu jeder Zeit nachvollziehen zu k?nnen.}
			\label{fig: Rstudio}
		\end{center}
	\end{figure}
	
	
	
	\chapter{Dateien, Proben und Populationen}
	
	Die folgenden vier Kapitel sind den vier Typen der statistischen Analyse zugewiesen, die in der Einleitung bereits genannt wurden: deskriptive Statistik, Inferenzstatistik, vorhersagende Statistik und experimentelle Planung. 
	
	\section{Stichproben, Populationen und der Vorgang der Datenerzeugung}
	
	Der eigentliche Grund der f?r statistische Berechnungen spricht, ist, dass die Daten, die wir erhalten, sehr zuf?llig erscheinen. Aber wie entsteht diese Zuf?lligkeit?
	
	Man stelle sich vor, \marginnote{Eine Population ist die Zusammenstellung aller Beobachtungen, die man h?tte machen k?nnen. Eine Stichprobe ist die Beobachtung, die man tats?chlich gemacht hat.} man w?re in die durchschnittliche Wachstumsrate der B?umen in Deutschland w?hrend zwei aufeinanderfolgenden Jahren interessiert. Idealerweise sollte man alle B?ume per Hand messen und w?re somit ohne statistische Berechnungen ausgekommen. In der Praxis ist man jedoch kaum in der Lage dies durchzuf?hren. Um die durchschnittliche Rate ermitteln zu k?nnen, muss man nun eine Auswahl an B?umen treffen und die Wachstumsrate aller dieser gew?hlten B?ume ermitteln. Der statistische Terminus f?r alle B?ume in Deutschland lautet "`Population"' und die Bezeichnung der ausgew?hlten gemessenen B?ume ist "`Stichprobe"'.
	
	Die \marginnote{Das W?hlen von Stichproben erzeugt Zuf?lligkeit.} Population an sich ist definiert und ?ndert sich nicht, jedoch k?nnte man bei jeder Untersuchung einer zuf?llig gew?hlten Stichprobe aus der Population andere Teilbereiche mit minimal unterschiedlichen Eigenschaften erhalten. Ein konkretes Beispiel: Man habe nur die M?glichkeiten um 1000 B?ume in Deutschland zu untersuchen. Man wird bei jeder zuf?llig gew?hlten Stichprobe mit 1000 B?umen aus der gesamten Population unterschiedliche durchschnittliche Wachstumsraten erhalten.
	
	Der\marginnote{Jedoch kommt nicht jede Zuf?lligkeit durch das W?hlen von Stichproben aus einer Population.} Vorgang des Stichproben-Festlegens aus einer Population erkl?rt, wie die Zuf?lligkeit in unseren Daten entsteht. Jedoch gibt es ein kleines Problem bei dieser ?berlegung, da dies nicht immer zutrifft, wenn man beispielsweise komplexere Zufallsprozesse betrachtet. Man gehe exemplarisch davon aus, dass man Daten z./,B. durch eine Person erh?lt, welche zu zuf?llig ausgew?hlten Punkten geht und daraus die Ausbreitung ermitteln m?chte (welche innerhalb von Minuten durch wechselnde Bew?lkung variieren kann). Man verwendet dazu ein Messger?t, das mit zuf?lliger Abweichung misst. Macht es da wirklich Sinn auf Daten zu vertrauen, die durch das Stichproben-W?hlen aus einer Gesamtpopulation mit verschiedenst m?glichen Beobachtungen entstanden sind?
	
	\marginnote{Eine modernere und allgemeinere Idee, welche das potentielle Entstehen von Daten beschreibt, ist das Konzept des "`datenerzeugenden Vorgangs"', wobei der Name bereits verr?t, was dahinter steckt: der datenerzeugende Vorgangs beschreibt, wie die Beobachtung einer zuf?llig gew?hlten Stichprobe entsteht und dabei zus?tzlich systematische und stochastische Prozesse mit einbezieht.}  Daf?r bezieht es die Eigenschaften mit ein, welche typischerweise als "`Stichprobenerhebung aus der Population"' bezeichnet werden, jedoch dies in umfassenderen Ausma?, indem es all die anderen Vorg?nge, die systematische und zuf?llige Muster im Datensatz entstehen lassen k?nnen, einschlie?t. In diesem Fall schlussfolgert man nicht die Umst?nde der Population aus der Stichprobe, sondern wir w?rden die Umst?nde des datenerzeugenden Prozesses aus den Stichproben-Beobachtungen, die durch diesen Prozess entstanden sind, schlie?en. 
	
	Egal, ob man in Populationen oder datenerzeugenden Prozessen denkt: Das Essenzielle aus diesem Abschnitt ist, dass es zwei Objekte gibt, die man strikt unterscheiden soll: zum Einen gibt es unsere Stichprobe. Man beschreibt sie meist durch ihre Zust?nde (Mittelwert, Minimum, Maximum), jedoch ist eine Stichprobe nicht das eigentliche Ziel. Letztendlich m?chte man lediglich die Umst?nde der Population / des datenerzeugenden Prozesses aus der Stichprobe schlussfolgern. Dazu kommen wir im n?chsten Abschnitt der Inferenzstatistik. Davor m?ssen wir jedoch noch einen genaueren Blick auf die Darstellung von Stichproben, beziehungsweise auf die Tatsachen, die wir beobachten, werfen.
	
	\section{Darstellung und Datenklassen}
	
	Ein typischer Datensatz beinhaltet meist mehrere Beobachtungen von verschiedensten Variablen (z./,B. Temperatur, Niederschlag, Wachstum). Man kann sich dabei eine Tabelle vorstellen, in der die Spalten die Variablen bezeichnen und die Reihen die unterschiedlichen Beobachtungen. Nat?rlich gibt es auch andere Datenstrukturen, jedoch ist diese die wohl H?ufigste.
	
	?blicherweise enthalten die Daten eine Variable auf der unser Fokus liegt, d./,h. wir m?chten herausfinden, wie sehr unsere Variable von den anderen Variablen beeinflusst wird. \marginnote{Die Response-Variable ist die Variable, f?r die wir herausfinden wollen, inwiefern sie von anderen Faktoren abh?ngt.}  Diese Variable wird als ``Response-Variable'' bezeichnet (manchmal auch abh?ngige Variable oder Ergebnisvariable), da wir wissen wollen, ob und wie diese untersuchte Variable variiert (Reaktion, Abh?ngigkeit) wenn sich etwas anderes ver?ndert. Diese anderen Variablen, die unsere untersuchte Variable beeinflussen, k?nnen unter anderem Umweltfaktoren (z./,B. Temperatur) oder Behandlungen (befruchtet vs. unbefruchtet) sein. \marginnote{Einflussvariablen sind solche, die die Response-Variable beeinflussen.} Diese anderen Variablen, die unsere untersuchte Variable beeinflussen, nennt man ``Einflussvariablen'' (Synonyme hierf?r w?ren erkl?rende Variablen, Kovariaten oder unabh?ngige Variablen). 
	
	In den \marginnote{Multivariate Statistik behandelt Response-Variablen mit mehreren Dimensionen, wie z./,B. Artenzusammensetzungen} meisten F?llen ist unsere Response-Variable eine einzelne Variable (beispielsweise eine einfache Zahl oder ein kategorisches Ergebnis), worauf wir uns nun konzentrieren. Manchmal gibt es jedoch F?lle, bei denen eine Response mehr als nur eine Dimension einnimmt, oder wenn man an einer Ver?nderung von mehreren Variablen gleichzeitig interessiert ist. Das Auswerten solcher Daten wird als multivariate Statistik bezeichnet. Diese Methoden werden jedoch hier nicht weiter aufgef?hrt, k?nnen aber bei Bedarf unter diesem \href{http://biometry.github.io/APES/Stats/stats50-MultivariateStatistics.html}{Link} nachgelesen werden.
	
	Weiterhin ist zu beachten, dass man die Variablenart unterscheiden muss; unabh?ngig davon, ob wir von Response- oder Einflussvariablen sprechen. Man unterscheidet hier: \marginnote{Variablen k?nnen stetig, unstetig oder kategorisch sein. Kategorische Variablen k?nnen geordnet, ungeordnet oder bin?r sein.}
	
	\begin{itemize}
		\item Stetig numerische Variablen (geordnet und stetig / real), z./,B. Temperatur
		\item Ganzzahlig numerische Variablen (geordnet, ganzzahlig). Hierzu z?hlt der wichtige Spezialfall der Z?hldaten, z./,B. 0,1,2,3, ...
		\item Kategorische Variablen (z./,B. eine feststehende Auswahlm?glichkeit wie beispielsweise rot, gr?n, blau), welche dann weiterhin unterteilt werden k?nnen in 
		\begin{itemize}
			\item Ungeordnete kategorische Variablen (Nominal) wie beispielsweise rot, gr?n, blau
			\item Bin?re (dichotome) Variablen (verstorben / ?berlebt, 0/1)
			\item Geordnete kategorische Variablen (klein, mittel, gro?)
		\end{itemize}
	\end{itemize}
	
	Hier ist es ?u?erst wichtig die Variablen ihren entsprechendem ``Typ'' zuzuweisen.\marginnote{?berpr?ft, ob ihr eure Variablen dem richtigen Typ zugewiesen habt, nachdem ihr sie in euer Statistikprogramm eingegeben habt.} Und falls man eine Statistik Software benutzt, muss man sicher stellen, dass der Typ auch korrekt erkannt wurde, nachdem die Daten eingegeben wurden, da viele Methoden die Variablen unterschiedlich behandeln, wenn sie numerischem oder kategorischem Typs sind.
	
	Aus Erfahrung wei? man, dass Anf?nger eher dazu neigen, Variablen als kategorisch einzuordnen, obwohl diese eigentlich stetig w?ren, z./,B. beim Einteilen von K?rpergewicht von Tieren in leicht, mittel und schwer.\marginnote{Verwende nie kategorische Variablen f?r Dinge, die ebenso als numerisch eingestuft werden k?nnen!} Eine Rechtfertigung daf?r ist meist, dass es ein ungewisses Messen vermeidet. Kurz gesagt: Das tut es ganz und gar nicht.Es ruft nur zus?tzliche Probleme hervor. Verwende nie kategorische Variablen f?r Dinge, die ebenso als numerisch eingestuft werden k?nnen!
	
	
	\vspace{1cm}
	\begin{fullwidth}
		\begin{mdframed}
			
			\textbf{In R:} 
			
			Um Daten darzustellen besitzt R eine grundlegende Datenstruktur, den Daten-Frame (data.frame). Ein Daten-Frame ist gleichzusetzen mit einer Tabelle mit Spalten, wobei jede Spalte einen anderen Typ haben kann. M?glichkeiten hier sind
			
			\begin{itemize*}
				\item ganzzahlig - selbsterkl?rend
				\item numerisch - kontinuierliche Nummern (Gleitkommazahl)
				\item boolean (=aussagenlogisch) - true / false
				\item Faktor - normalerweise ungeordnet, z./,B. rot, gr?n, blau. Kann auch geordnet sein (klein, mittel, gro?), wobei es hier manchmal ratsam w?re, diese als ganzzahlig einzustufen
			\end{itemize*}
			
			Desweiteren gibt es den Fall der ausbleibenden Beobachtung einer Variablen, auch wenn dies nicht wirklich ein Datentyp ist. Dies wird dann typischerweise mit "NA" betitelt. ?hnlich, jedoch nicht identisch ist "NaN" (not a number), was bei einer nicht ausf?hrbaren Rechnung als Ergebnis auftreten kann.
			
			Um Daten als data.frame in R-studio einzulesen, findet man im oberen rechten Teil "Import Dataset". Genaueres kann unter "Handling data in R" im Anhang~\ref{HandlingDataInR}, oder auf \href{http://biometry.github.io/APES/R/R20-DataStructures.html}{http://biometry.github.io/APES/R/R20-DataStructures.html} nachgelesen werden.
			
			Nachdem die Daten eingelesen wurden, ist es sehr wichtig die Spalten auf ihre richtigen Typen zu ?berpr?fen. Dies wird ausgef?hrt durch str(TheNameOfMyData), womit man kann die Spalten auf ihre Typen checken kann.
			
		\end{mdframed}
	\end{fullwidth}
	
	
	\chapter{Deskriptive Statistik und Visualisierung}
	
	Deskriptive Statistik\marginnote{Wie man Daten erstellt wird sp?ter noch detaillierter im Kapitel ~\ref{cha: design of experiments} Versuchsplanung behandelt.} behandelt die Zusammenfassung und Veranschaulichung von (die durch Stichproben gew?hlten) Daten
	
	\section{Ma?zahlen der Statistik}
	
	Ma?zahlen der Statistik\marginnote{Ma?zahlen der Statistik fassen die Daten zusammen} sind numerische Berechnungen, die Datens?tze zusammenfassen. Dies dient zur kompakten Veranschaulichung der Eigenschaften eines Datensatzes.
	
	\subsection{Zusammenfassen einer einzelnen stetigen Variable}
	
	Eine ?bliche Situation bei der wir von den Ma?zahlen der Statistik Gebrauch machen, ist die wiederholte Beobachtung einer stetigen Variable. Als Beispiel kann man sich hier vorstellen, man habe 2000 B?ume gemessen und anschlie?end erneut vermessen. Man konnte eine Vorkommen an zunehmendem Durchmesser beobachten (siehe Abb.\ref{fig: data distribution}).

\begin{figure}[htbp]
\begin{center}
\begin{Schunk}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-2-1} \end{Schunk}
\caption{Eine Verteilung von beobachteten zunehmenden Durchmessergr??en (graue Balken). Wir nehmen an (in diesem Fall wissen wir es), dass diese Werte von wahren Verteilungen stammen (Population oder datenerzeugender Prozess) die hier in einer rot-gestrichelten Linie angedeutet werden. Wenn wir nun mehr Daten aufzeichnen w?rden, w?rden sich die grauen Balken der wahren Verteilung immer mehr ann?hern.}
\label{fig: data distribution}
\end{center}
\end{figure}

Wie kann man nun die Eigenschaften der beobachteten Stichprobe zusammenfassen? Ein paar grundlegende Eigenschaften w?ren beispielsweise das Minimum und das Maximum, der Mittelwert, oder der Modalwert (die Maximalverteilung, d.h. der Wert der h?chsten Beobachtungsdichte). Au?erdem  gibt es zwei weitere Ma?zahlen, die ebenso oft Gebrauch finden: Moment und Quintal.


Der Begriff 'Moment' mag vielleicht nicht jedem gel?ufig sein, vermutlich wurde aber schon einmal das erste und zweite Moment der Verteilung berechnet. Diese sind ebenfalls unter den Bezeichnungen Mittelwert und Standardabweichung bekannt. Allgemein wird das n-te Moment $\mu_n$ einer Verteilung $f(x)$ um einen Wert c definiert als 

\begin{equation}
\mu_n(c) = \int_{-\infty}^{\infty} f(x) (x - c)^n dx
\end{equation}

oder, f?r eine endliche Anzahl an Beobachtungen 

\begin{equation}
\mu_n(c) = \frac{1}{N}\sum_{i=1}^N (x_i - c)^n dx
\end{equation}

Das erste Moment mit c=0, ist der Mittelwert. F?r die folgenden h?heren Momente ist es ?blich die Zentralmomente zu betrachten, die man durch das Setzen von c auf den Mittelwert erh?lt, da ihre Werte einfacher als Indikatoren f?r die Verteilungsform zu interpretieren sind.\footnote{Um die Varianz abzusch?tzen, ersetzt man oft den Term 1/N durch den Bias-korrigierten Term 1/(N-1).} Die drei h?heren Zentralmomente werden Varianz (n=2, identisch mit dem Quadrat der Standardabweichung, Messgr??e der Streuung),Schiefe (n=3, Messgr??e f?r die Asymmetrie in der Verteilung) und W?lbung (n=4) genannt. 

Quantilen stellen die zweite Zentralklasse der Ma?zahlen-Statistik dar, um die kontinuierliche Verteilung zu beschreiben. Wenn wir eine Verteilung wie in der oben gezeigten Abbildung vorfinden, kann man sich die Frage stellen: Welcher ist der entscheidende Wert, der den Datensatz in zwei H?lften trennt, sodass eine H?lfte der beobachten Daten kleiner und die andere H?lfte gr??er als dieser Wert ist?\marginnote{Eine H?lfte der Daten ist kleiner und die andere H?lfte ist gr??er als die 0.5 Quantile, welches auch als Medianwert bezeichnet wird} Dieser Punkt wird als Medianwert, oder auch als 0.5 Quantile bezeichnet. Allgemeiner kann man sagen, dass die 0.x Quantile der Wert ist, an dem der Anteil 0.x des Datensatzes kleiner ist. 

\subsection{Korrelation - Erl?uterung der Abh?ngigkeit stetiger Variablen}

Ein weiterer wichtiger Bereich der Ma?zahlen-Statistik ist die Korrelation. Korrelationsstudien messen die Abh?ngigkeit von stetigen Variablen. Leider gibt es eine Menge Korrelations-Messgr??en, die es zu unterscheiden gilt. Die zwei wichtigsten sind:

\paragraph{Lineare Koeffizienten:}Lineare Koeffizienten, mit dem "Pearson'schen Korrelationskoeffizienten" als wohl H?ufigsten, ermitteln die lineare Abh?ngigkeit zwischen zwei Variablen. Der Pearson'sche Korrelationskoeffizient wird wegen seiner schnellen Berechnung und leichten Interpretation am h?ufigsten verwendet. Jedoch kann es hier zu Fehlern kommen, wenn die Variablen nicht linear abh?ngig voneinander sind. Fig.~\ref{fig: correlation}.

\paragraph{Rangkorrelationskoeffizient:} Rangkorrelationskoeffizient, wie zum Beispiel der ``Spearman'sche Rangkorrelationskoeffizient'' und der ``Kendall Tau Rangkorrelationskoeffizient'' ermitteln, wie genau die Variablen gemeinsam tendenziell steigen oder fallen, ohne hierbei das Ausma? oder die Linearit?t ihrer Steigung zu beachten. Diese werden bevorzugt, wenn man von zueinander nicht-linearen Variablen ausgeht. 

\paragraph{Starke Korrelation != bedeutender Einfluss:} Siehe auch Fig.~\ref{fig: correlation}; ist ein oft falsch verstandener Zustand der Korrelation und Abh?ngigkeit - ein hoher Korrelationskoeffizient bedeutet nicht, dass eine Variable eine starke Reaktion auf eine andere bewirkt. Um eine hohe Korrelation zu erreichen braucht es nur eine geringe Streuung um die Linie (siehe mittlere Reihe - die Auswirkung ist anders, aber die Korrelation bleibt gleich). 


\begin{figure}[htbp]
\begin{center}
\begin{Schunk}
\begin{Soutput}
Error in library(mvtnorm): there is no package called 'mvtnorm'
\end{Soutput}
\begin{Soutput}
Error: konnte Funktion "rmvnorm" nicht finden
\end{Soutput}
\begin{Soutput}
Error in RotNormal(200, c(0, pi/12, pi/6, pi/4, pi/2 - pi/6, pi/2 - pi/12, : konnte Funktion "rmvnorm" nicht finden
\end{Soutput}
\begin{Soutput}
Error in Others(800): konnte Funktion "rmvnorm" nicht finden
\end{Soutput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-3-1} \end{Schunk}
\caption{Beispiele einer m?glichen Korrelation mit dem Pearson'schen Korrelationskoeffizienten. Beachte, dass viele Datens?tze, die eine klare Abh?ngigkeit zwischen Variablen aufweisen, einen Pearson'schen Korrelationskoeffizienten von 0 aufweisen, da die Abh?ngigkeit nicht linear ist.}
\label{fig: correlation}
\end{center}
\end{figure}

\subsection{Kreuztabellen - Erl?uterung unstetiger Ergebnisse mehrerer Variablen}

Zu guter Letzt\marginnote{Dieser Datensatz von Berkeley ist ein ber?hmtes Beispiel f?r das Simpson-Paradoxon. Weitere Informationen auf Wikipedia ?ber diese wichtige statistische Falle.} gibt es noch die klassischen Kreuztabellen, um bin?re oder kategorische Daten zu beschreiben. Hier ist ein Auszug eines ?blichen Datensatzes aus R ?ber Sammeldaten von Hochschulbewerber in Berkeley aus dem sechst-gr??ten Departments im Jahre 1973, geordnet nach Zulassung und Geschlecht. Hier wird nur das erste Department gezeigt.
.

\begin{Schunk}
\begin{Sinput}
UCBAdmissions[,,1]
\end{Sinput}
\begin{Soutput}
          Gender
Admit      Male Female
  Admitted  512     89
  Rejected  313     19
\end{Soutput}
\end{Schunk}


\vspace{1cm}
\begin{fullwidth}
\begin{mdframed}
    
\textbf{In R:} 

F?r die vielseitigen Berechnungsm?glichkeiten der deskriptiven Statistik in R, siehe \href{http://www.uni-kiel.de/psychologie/rexrepos/rerDescriptive.html}{hier}

\end{mdframed}
\end{fullwidth} 


\section{Visualisierung}

\marginnote{Gebe ?anscombe in R ein, um den Code zu sehen, der diese Plots ausgibt und um die statistischen Eigenschaften des Datensatzes zu berechnen.}

Ma?zahlen sind sehr n?tzlich, k?nnen aber auch zum Problem werden. Ein bekanntes Beispiel daf?r ist das Anscombe Quartett, ein hypothetischer Datensatz aus vier Beobachtungen, die identische ?bliche Ma?zahlen aufweisen, wie z.B. Mittelwert, Varianz, Korrelation, Regressionslinie, etc. \citep{Anscombe-Graphsinstatistical-1973}. Hier ist es ?u?erst n?tzlich zus?tzlich eine graphische ?bersicht zu den berechneten Ma?zahlen der Daten zu erhalten.

\begin{figure}[htbp]
\begin{center}
\begin{Schunk}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-5-1} \end{Schunk}
\caption{ein hypothetischer Datensatz aus vier Beobachtungen, die identische ?bliche Ma?zahlen aufweisen, wie z.B. Mittelwert, Varianz, Korrelation, Regressionslinie, etc.}
\label{fig: Anscombes Quartet}
\end{center}
\end{figure}


\subsection{Grunds?tze der Visualisierung}

Der Grundsatz\marginnote{Beispiele f?r verzerrte Grafiken \href{https://en.wikipedia.org/wiki/Misleading_graph}{siehe}} von Grafiken und Darstellungen  ist die Daten so einsehbar und wahr wie m?glich darzustellen. Der Leser sollte einen bestm?glichen ?berblick in k?rzester Zeit ?ber die Daten erhalten. Zus?tzlich sollten die Graphen nat?rlich auch anschaulich sein. Vorab ein paar generelle Tipps, die vielleicht helfen k?nnten:

\begin{itemize}
\item Einfach ist besser, als kompliziert
\item Vermeide ?bertriebene Farben. Graphen sollten wenn m?glich auch in schwarz-wei? leserlich sein (benutze einen Farbgradienten, der gleichzeitig ein Intensit?tsgradient ist; benutze zus?tzlich zu Farben auch gestrichelte Linien). Wenn dein Graph auf Farben basiert, achte darauf welche zu verwenden, die auch Menschen mit einer Rot-Gr?n-Schw?che erkennen k?nnen.
\item Ehrlichkeit: vermeide Verzerrungen. Benutze quadratische Formen, au?er es gibt besondere Gr?nde. Achsen sollten bei 0 beginnen, au?er es gibt gute Gr?nde, die dagegen sprechen. Verwende die gleiche Skala bei der Darstellung mehrerer Grafiken, wenn es keine Gr?nde gibt, die dagegen sprechen. 
\item Manipuliere deine Grafiken nicht!
\item Ausgabe in einem Vektor-Format (pdf, eps, svg)
\end{itemize}

\begin{figure}[htbp]
\begin{center}

\setkeys{Gin}{width=\textwidth}
\begin{Schunk}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-6-1} \end{Schunk}
\caption{Vier typische Plot-Typen, von oben links nach unten rechts: a) Liniendiagramm, repr?sentiert stetige Messungen einer Variablen; b) Streudiagramm, repr?sentiert eine Beziehung zwischen zweier stetigen Variablen; c) Balkendiagramm, repr?sentiert Messungen in unstetigen Gruppen / Variablen; d) Boxplot, repr?sentiert stetige Messungen in unstetigen Gruppen.}
\label{fig: exaple plots}
\end{center}
\end{figure}


\subsection{Graphen-Typen}

Es gibt eine gro?e, fast unendliche Bandbreite an verschiedenen visuellen Darstellungen von Datens?tzen. Im Folgenden werden nun vier h?ufig verwendete Graph-Typen gezeigt. 

\paragraph{Liniendiagramme:} Liniendiagramme werden benutzt, um stetige, geordnete Messwerte darzustellen. Typische Beispiele hierf?r w?ren Zeitreihen, stetige Parameterver?nderungen oder mathematische Funktionen. Beispiel siehe Fig.~\ref{fig: exaple plots} a.

\paragraph{Streudiagramme:} Streudiagramme veranschaulichen zwei stetige Variablen die paarweise gemessen wurden. Ein typisches Beispiel hierf?r w?re das wiederholte Messen von verschiedenen Variablen mit der Absicht herauszufinden, ob diese korrelieren.Beispiel siehe Fig.~\ref{fig: exaple plots} b.

\paragraph{Balkendiagramme:} Balkendiagramme beinhalten Informationen (Z?hlungen oder stetige Variablen) ?ber unstetige Gruppen. Beispiel siehe Fig.~\ref{fig: exaple plots} c.

\paragraph{Boxplots:} Boxplots benutzt man h?ufig bei der Verteilung einer stetigen Variable ?ber mehrere unstetige Gruppen. Klassischerweise bestehen sie aus einer Box, 'Whiskers' (Linien) und gegebenfalls Punktewerte um die 'Whiskers'. Deren Bedeutung ist von der benutzten Software abh?ngig, mit der man die Plots gestaltet hat. Normalerweise bedeckt die Box die in der Mitte liegenden 50\%, mit dem angedeuteten zentralen Medianwert. Die Linien sollen zur Absch?tzung der Daten-Bandbreite dienen, Ausrei?er ausgenommen. Nat?rlich liegt es im Auge des Betrachters, was als Ausrei?er angesehen wird und was nicht. Die exakte Definition von Whiskers besagt, dass die weit entfernteste Beobachtung weniger oder gleich der oberen Quantile plus 1,5 der L?nge der Interquartilenbreite ist. Beispiel siehe Fig.~\ref{fig: exaple plots} d.

\vspace{1cm}
\begin{fullwidth}
\begin{mdframed}
    
\textbf{In R:} 

Es gibt viele gute Einleitungen in Graphiken mit R, sodass diese Details hier nicht weiter aufgef?hrt werden. Zu Beginn empfehle ich diese  \href{https://github.com/florianhartig/ResearchSkills/tree/master/Labs/Statistics/Practicals/GraphicsInR}{?bungen zum graphischen Gestalten mit R}. Diese sind begleitend zu diesem Skript oder auch zu

\begin{itemize*}
  \item \href{http://www.statmethods.net/graphs/index.html}{QuickR}
  \item \href{http://shinyapps.org/apps/RGraphCompendium/index.php}{RGraphCompendium}
  \item \href{http://www.uni-kiel.de/psychologie/rexrepos/rerDiagrams.html}{rexrepos}
\end{itemize*}

\end{mdframed}
\end{fullwidth} 


\chapter{Inferenzstatistik}

\marginnote{Inferenzstatistik ist das Ziehen von Schl?ssen aus Beobachtungen durch statistische Methoden} 

Inferenzstatistik behandelt das Schlussfolgern, z.B. das R?ckschl?sse ziehen aus Beobachtungen. Ein Beispiel einer solchen Folgerung w?re beispielsweise die Beobachtung, dass 15 von 20 Testobjekte, die eine bestimmte Medikation erhielten (Behandlungsgruppe), eine Verbesserung ihres Zustandes zeigten --> Statistische Folge: Wir k?nnen davon ausgehen, dass es eine Wahrscheinlichkeit von X gibt, dass die Medikation einen positiven Effekt hat.


\section{Datenerzeugendes Modell}

\marginnote{Inferenzstatistik ist nicht immer, aber meist mit dem Prinzip des datenerzeugenden Modells verkn?pft}

Eine zentrale Idee von vielen Methoden der Inferenzstatistik ist das Prinzip des datenerzeugenden Modells. Kurz gesagt beinhaltet unser datenerzeugendes Modell unsere festgelegte Annahme, wie die Daten entstehen (normalverteiltes Rauschen, lineare Reaktion). Daraus kann man dann abh?ngig unserer festgelegten Annahme die unbekannten Gr??en (Unterschiede zwischen Behandlungsgruppe und Kontrollgruppe) berechnen (schlussfolgern).

\marginnote{In der Statistik verwendet man oft das Wort "`behandelt"' um Ver?nderungen in experimentellen Einheiten zu beschreiben. Hier w?ren die zwei Musikarten "`Behandlung"' und das "`Nichts-tun"' die Kontrolle} 

Man stelle sich vor man m?chte herausfinden, ob das Pflanzenwachstum von Musik beeinflusst werden kann. Hierzu nehmen wir zwei T?pfe, jeder mit einer Pflanze, wobei eine mit klassischer und eine andere mit Heavy Metal -Musik beschallt wird. Eine der beiden wird zwangsl?ufig h?her wachsen, jedoch k?nnte dies reiner Zufall sein, da es immer Variationen in Wachstumsraten gibt.

Somit bedarf es mehrerer Wiederholungen. Nun nehmen wir im unten aufgef?hrten Beispiel 30 T?pfe.

\begin{figure}[htbp]
\begin{center}
\begin{Schunk}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-7-1} \end{Schunk}
\caption{Wachstumsmessungen unter verschiedenen Behandlungsweisen}
\label{fig: plant growth music}
\end{center}
\end{figure}

\marginnote{Beachte die Interpretation eines Boxplots - die dickere Linie in der Mitte der Box ist der Medianwert. Die Box bedeckt die zentrale 0,5 Quantile der Verteilung}
Es scheint Unterschiede zwischen den drei F?llen zu geben, jedoch gab es auch Abweichungen in den Wachstumsraten innerhalb der einzelnen Behandlungsguppen (durchschnittlich haben wir hier sieben Beobachtungen pro Behandlung). Somit ist es immer noch m?glich, dass die Unterschiede in den Beobachtungen durch Zufall entstanden sind.

Wenn wir genaue Aussagen ?ber die Wahrscheinlichkeit der Unterschiede zwischen den zwei behandelten und der Kontrollgruppe treffen m?chten, m?ssen wir ein Modell erstellen, welches die stochastische Abweichung in den Daten beschreibt. Dies erlaubt uns wiederum Eigenschaften, wie z.B. die Zufallswahrscheinlichkeit der beobachteten Unterschiede berechnen zu k?nnen. Diese Annahmen sind das, was wir als statistisches Modell bezeichnen (oder auch: stochastische Verfahren, datenerzeugendes Modell). 

Die ?blichere Modellart f?r solche Zwecke ist das parametrische statistische Modell. F?r die Daten, die wir hier haben, w?rde das parametrische statistische Modell annehmen, dass es eine durchschnittliche Wachstumsrate f?r jede Behandlungsart (Kontrolle, klassische und Heavy Metal Musik) gibt, jedoch das Wachstum jeder individuellen Pflanze mit einer normalverteilten Abweichung um ihre behandlungsspezifische durchschnittliche Wachstumsrate variiert. Die Parameter dieses Modells sind die unbekannten durchschnittlichen Wachstumsraten und die Abweichung der Normalverteilung. Diese Parameter werden dann mit Methoden, die hier in diesem Kapitel erkl?rt werden, an die Daten angepasst und basieren auf der Berechnung f?r z.B. die Wahrscheinlichkeit der Datenresultate, wenn keine Unterschiede zwischen den Gruppen w?ren.

Eine andere M?glichkeit, um datenerzeugende Modelle zu erstellen, sind nicht-parametrische Methoden.\marginnote{Die nicht-parametrische Statistik versucht Vermutungen ?ber datenerzeugende Prozesse zu vermeiden. Normalerweise entsteht der datenerzeugende Prozess durch das Imitieren der eigentlichen Daten, z.B. durch das erneute Pr?fen von Methoden.} Nicht-parametrische Methoden umgehen die Notwendigkeit einer Annahme z.B. ?ber die Streuung der Daten durch das Randomisieren (zuf?lliges Anordnen) oder das wiederholte Pr?fen des Datensatzes. Wie funktioniert das? F?r das Pflanzenwachstum beispielsweise l?sst sich diese Frage wie folgt beantworten: Wie wahrscheinlich das erneute Erhalten der beobachteten Ergebnisse, wenn keine Unterschiede zwischen den Gruppen w?ren und ohne das Anstellen von Vermutungen ?ber die Streuung? Hierf?r werfen wir einfach alle Beobachtungen ungeachtet ihrer Behandlungsart in einen Topf und verteilt sie erneut zuf?llig in die drei Behandlungsgruppen. Wenn wir dies nun oft wiederholen (z.B. 1000 mal) kann man einen guten Eindruck davon bekommen, wie wahrscheinlich es ist die beobachteten Unterschiede zu erhalten, wenn die Behandlungen keinen Effekt h?tten.

Nicht-parametrische Methoden sind ein wichtiger Bestandteil moderner Statistik.\marginnote{Die Feinsinnigkeit der parametrischen Methoden baut auf das Treffen von Annahmen, was in einer Art und Weise zus?tzliche Daten darstellt. Nat?rlich basieren dann alle Ergebnisse auf der Richtigkeit dieser Vermutungen. Wie man parametrische Vermutungen ?berpr?ft werden wir sp?ter in diesem Kapitel behandeln.} Ihr Vorteil liegt wohl in der Tatsache, dass sie keine Vermutungen anstellen. Andererseits sind parametrische Methoden meist viel schneller und sind, falls ihre Annahmen korrekt sind, mit der selben Menge an Daten viel aussagekr?ftiger und feinf?hliger, wodurch sie viel wahrscheinlicher einen Effekt, falls vorhanden, erkennen k?nnen. Aufgrund der letzten beiden Argumente sind momentan parametrische Methoden die Grundlage der meisten statistischen Analysen.


\section{Inferentielle Outputs}

Auf dem datenerzeugendem Modell basierend (parametrisch oder nicht-parametrisch) k?nnen wir nun verschiedene inferentielle Vorgehensweisen anwenden, um R?ckschl?sse ?ber unsere Daten (in unserem Fall: Um entscheiden zu k?nnen, ob Musik einen Unterschied macht, oder nicht) zu ziehen. In der normalen Statistik gibt es vorwiegend zwei inferentielle Vorgehensweisen, die auf alle m?glichen Arten von Konfigurationen und Modelle angewendet werden. Die Outputs dieser zwei Vorgehensweisen sind: p-Werte und Maximum-Likelihood-Sch?tzungen. Ein weiteres drittes Verfahren wird momentan immer beliebter - die nachtr?glich, durch Bayes ermittelte Inferenz. Auf diese werde ich noch am Ende dieses Abschnittes eingehen.

\subsection{p-Werte}

Die Verwendung des p-Wertes ist eng mit der Inferenzmethode der Null-Hypothesen Signifikanzpr?fung (null hypothesis significance testing, NHST) verbunden. Die Idee, die dahinter steckt, ist folgende: wenn wir gewisse Daten beobachten und ein statistisches Modell haben, k?nnen wir dieses statistische Modell benutzen, um eine vorgegebene Hypothese ?ber das Entstehen der Daten zu pr?zisieren. F?r das Beispiel der Pflanzen und der Musik k?nnte unsere Hypothese so lauten: Musik hat keinen Einfluss auf Pflanzen; alle beobachteten Unterschiede basieren auf zuf?lligen Abweichungen zwischen den Individuen. Dieses Szenario wir als Nullhypothese bezeichnet. \marginnote{Eine Nullhypothese $H_0$ ist ein vorgegebenes Szenario, das Vorhersagen ?ber erwartete Wahrscheinlichkeiten von verschiedenen Beobachtungen macht.} Auch wenn es ?blich ist, die Annahme keinerlei Auswirkungen auf die beobachteten Objekte als Nullhypothese zu setzen, ist es tats?chlich die eigene Entscheidung und man genauso gut die Vermutung "`klassische Musik verdoppelt die Wachstumsrate der Pflanzen"' als Nullhypothese setzen. Es liegt im Ermessen des Analytikers, was als Nullhypothese betrachtet werden soll. Dies ist auch der Grund f?r die gro?e Auswahlm?glichkeit an verf?gbaren Tests. Wir werden noch einige davon im folgenden Kapitel ?ber wichtige Hypothesentests kennen lernen.

Wenn wir uns f?r eine Nullhypothese entschieden haben, berechnen wir die Wahrscheinlichkeit f?r dieses oder ein extremeres Beobachten der Daten in diesem Szenario. \marginnote{Der p-Wert ist die Wahrscheinlichkeit die Daten oder extremere Daten unter unserer Nullhypothese beobachten zu k?nnen.} 

\begin{equation}
p := p(d >= D_{obs} | H_0)
\end{equation}

Wenn der p-Wert unter eine gewisse Schwelle sinkt (Das Signifikanzlevel $\alpha$), spricht man von einem signifikantem Beweis, um die Nullhypothese abzuweisen. Die Schwelle $\alpha$ ist eine Vereinbarung, in der ?kologie ?blicherweise 0.05, sodass ein p-Wert kleiner als 0.05 ein Abweisen der Nullhypothese veranl?sst. \marginnote{Wenn p<0.05, haben wir signifikante Beweise f?r ein Abweisen der Nullhypothese.} 

Ein Problem der Hypothesentests und der p-Werte ist die notorische Fehlinterpretation der Ergebnisse. Der p-Wert ist NICHT die Wahrscheinlichkeit, dass die Nullhypothese wahr, oder die Alternativhypothese falsch ist; auch wenn viele Autoren diesen Fehler bei ihrer Interpretation gemacht haben, wie z.B. \citep[][]{Cohen-earthisround-1994}. Eher kann man den p-Wert als eine Kontrolle der Falsch-Positiven-Rate ansehen (Typ I-Fehler). Wenn man Hypothesentests mit einem $\alpha$ -Level von 0.05 auf Zufallsdaten anwendet, erh?lt man exakt 5\% Falsch-Positive. Nicht mehr und auch nicht weniger.  

\subsection{Maximum-Likelihood-Sch?tzung}

Eine zweite Variante der Ergebnisdarstellung, welche bei den meisten statistischen Methoden verwendet wird, ist das Sch?tzen von Maximum-Likelihood Parametern. Zusammenfassend kann man sagen, dass die Maximum-Likelihood-Sch?tzung (maximum-likelihood estimate (MLE)) die beste Sch?tzung f?r Parameter in unserem Modell ist (z.B. Unterschiede zwischen den Behandlungsarten und der Kontrolle, wie in unserem Beispiel).


Genauer gesagt wird die Wahrscheinlichkeit in der Statistik als Funktion der Modellparameter $\theta$ beschrieben als

\begin{equation}
L(\theta) := p(dD_{obs} | M(\theta))
\end{equation}

, z.B. als die Funktion die man erh?lt, wenn man die Wahrscheinlichkeit der erhaltenen beobachteten Daten bei ver?nderten Modellparameter berechnet.

Die Maximum-likelihood-Sch?tzung\marginnote{Hier ist zu beachten, dass die Maximum-likelihood-Sch?tzung ein Parametersatz ist, f?r den die Daten am Wahrscheinlichsten sind, nicht jedoch der wahrscheinlichste Parametersatz!} ist weiterhin definiert als eine Kombination von Parametern oder Modellannahmen, f?r welche die Wahrscheinlichkeit maximal ist. W?hrend der p-Wert die Wahrscheinlichkeit der beobachteten 
oder extremeren Daten unter einer festgelegten (Null-) Hypothese ist, gibt uns die Maximum-likelihood-Sch?tzung die "`Hypothese"' mit der h?chsten Wahrscheinlichkeit unsere beobachteten Daten zu erhalten.

Die Maximum-likelihood-Sch?tzung ist nur ein einzelner Parameterwert.\marginnote{Eine Punktsch?tzung ist vergleichbar mit einer einzelnen besten Sch?tzung.} Diese Art Sch?tzung wird oft Punktsch?tzung genannt. Jedoch ist eine Punktsch?tzung oft unbrauchbar, wenn wir nicht wissen wie genau sie ist.\marginnote{Konfidenzintervalle bieten einen Unsicherheitssch?tzwert um die Punktsch?tzung herum.} Deswegen werden Parametersch?tzungen immer mit Konfidenzintervallen angegeben. Salopp kann man sagen, dass das 95\% Konfidenzintervall eines Parameters eine wahrscheinliche Reichweite f?r diesen Bereich ist. Verwirrend ist hier, dass dies nicht das Intervall ist, in dem der richtige Parameter mit 95\% Wahrscheinlichkeit liegt. Vielmehr beinhaltet das Standard 95\% Konfidenzintervall bei wiederholten Experimenten zu 95\% aller F?lle den richtigen Wert. Dies ist ein kleiner, aber entscheidender Unterschied. Jedoch machen wir uns hier?ber nun keine weiteren Gedanken. Das Konfidenzintervall ist der ungef?hre Bereich, in dem wir den korrekten Parameter erwarten. 

\subsection{Bayes Verfahren}

Um unsere\marginnote{Bayes'sche Verfahren berechnen eine dritte Gr??e, die posteriore Wahrscheinlichkeit. Auch wenn man diese auf jedes Modell anwenden kann, benutzt man sie ?blicherweise bei erweiterten statistischen Berechnungen.} ?bersicht der schlussfolgernden Methoden zu komplettieren, fehlt noch eine, die erw?hnt werden sollte - Bayes'sche Methoden berechnen eine Gr??e, die sich die posteriore Parametersch?tzung (posterior parameter estimate) nennt. Diese ist ?hnlich, jedoch nicht identisch zu der vorherigen Parametersch?tzung. N?heres ist hier nicht von N?ten, bei Bedarf und Interesse kann jedoch meine Seite weiterhelfen \citep{Gelman-BayesianDataAnalysis-2003} \href{http://florianhartig.github.io/LearningBayes/}{Learning Bayes}.

\subsection{Verschiedene Methoden != verschiedene Modelle}

Wir wissen nun, dass es drei verschiedene Gr??en gibt, die Statistiker typischerweise berechnen: p-Werte, Maximum-likelihood und die Posteriori. Man kann bei gegebenen datenerzeugenden Prozessen immer jede einzelne davon berechnen.

Ich\marginnote{ANOVA , T-Tests und lineare Regression sind nur unterschiedliche Begutachtungen des selben Modells} formuliere diesen Punkt konkreter, da f?lschlicherweise viele Menschen glauben sie benutzen unterschiedliche Modelle, wobei sie lediglich unterschiedliche Wege nutzen, um diese zu begutachten. Ein Beispiel hierf?r sind ANOVA, T-Tests und die lineare Regression. Alle basieren auf ein und dem selben datenerzeugenden Prozess - einige festgelegte Auswirkungen zwischen Gruppen und obendrein ein unabh?ngiger und identischer normalverteilter Fehler. ANOVA und T-Tests legen verschiedenste Nullhypothesen fest und die lineare Regression sucht nach dem Maximum-likelihood-Sch?tzwert. Hier k?nnte man bei Bedarf noch die Bayes'sche Posteriori berechnen. 

\section{Wichtige Hypothesentests}

Nachdem jetzt die grundlegenden statistischen Datenausgaben besprochen wurden, gehen wir nun in die Praxis ?ber, um die zwei wohl h?ufigsten Hypothesentests kennen zu lernen - den T-Test und ANOVA. Wie bereits erw?hnt, basieren sie beide auf dem selben datenerzeugenden Prozess, legen jedoch geringf?gig unterschiedliche Nullhypothesen fest.

\subsection{T-Test}

Ein T-Test testet die Unterschiede der Mittelwerte von zwei normalverteilten Stichproben; oder im Falle einer einzigen Stichprobe zwischen 0 und den Mittelwert der Stichprobe.\marginnote{Um bei unserer vorhergehenden Einteilung zu bleiben, w?rden wir unsere Response-Variable als stetig und den Pr?diktor als kategorisch bezeichnen (Gruppe 1 oder Gruppe 2); oder im Falle einer einzelnen Gruppe gibt es keinen Pr?diktor.} Erneut ist hier das zugrundelegende Modell das einer Normalverteilung mit der Nullhypothese, dass es keine Unterschiede zwischen den Mittelwerten der zwei normalverteilten Gruppen gibt, bzw. dass der Stichproben Mittelwert 0 ist, wenn wir nur eine Gruppe betrachten. Desweiteren sind Software-abh?ngig oft eine Reihe an Anpassungen m?glich, z.B. eine Lockerung der Annahme, dass die zwei Gruppen die selbe Varianz aufweisen. Hier folgt nun ein Beispiel in R, mit klassischen Daten von \citet{Student-probableerrormean-1908}. Die Daten zeigen die Wirkung von zwei Schlafmitteln (gesteigerte Anzahl an Schlafstunden verglichen mit der Kontrolle) an 10 Patienten. 

\begin{figure}[htbp]
\begin{center}
\begin{Schunk}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-8-1} \end{Schunk}
\caption{Daten von \citet{Student-probableerrormean-1908}}
\label{fig: Student Sleep Data}
\end{center}
\end{figure}

\begin{Schunk}
\begin{Sinput}
## Traditional interface
with(sleep, t.test(sleep$extra[sleep$group == 1], extra[group == 2]))
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
## Formula interface
t.test(extra ~ group, data = sleep)
\end{Sinput}
\begin{Soutput}

	Welch Two Sample t-test

data:  extra by group
t = -1.8608, df = 17.776, p-value = 0.07939
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -3.3654832  0.2054832
sample estimates:
mean in group 1 mean in group 2 
           0.75            2.33 
\end{Soutput}
\end{Schunk}

Beachte, dass die Datenausgabe einen p-Wert (H0 = kein Unterschied), aber auch einen Maximum-likelihood-Sch?tzwert der Mittelwertsvergleiche, zusammen mit den Konfidenzintervallen bietet. Dies geht weit ?ber den klassischen T-Test hinaus. Vermutlich nahmen die Programmierer an, dass man zus?tzlich den besten Sch?tzwert f?r die Mittelwertsunterschiede haben m?chte.

Vorschlag f?r das Anzeigen des Ergebnisses: p>0.05: Unterschiede zwischen den Gruppen waren nicht signifikant. p<0.05: Wir erhielten einen Unterschied von X +- Konfidenzintervall zwischen den Gruppen (p-Wert f?r die Unterschiede eines T-Tests mit X). 

\subsection{Varianzanalyse (ANOVA)}

ANOVA (analysis of variance) oder Varianzanalyse kann von verschiedenen Personen unterschiedlich verstanden werden. Die Standard-ANOVA macht grunds?tzlich die gleichen Annahmen wie ein T-Test (normalverteilte Resonanz), jedoch f?r mehr als zwei Gruppen. Genauer gesagt testet es, ob die gemessene Resonanz (z.B. eine abh?ngige Variable) von einem oder mehreren kategorischen Variablen mit zwei oder mehreren interagierenden Ebenen beeinflusst wird. Eine Wechselwirkung\marginnote{Eine Wechselwirkung: eine Variable ver?ndert die Auswirkung einer anderen Variablen} zwischen zweier Variablen bedeutet, dass sich der Wert einer erl?uternden Variable darauf auswirkt, wie sehr eine andere erl?uternde Variable die Resonanz beeintr?chtigt.

W?hrend der Begriff ANOVA meist mit der oben genannten Erkl?rung in Verbindung gebracht wird (welche der von T-Tests / linearer Regression entspricht, siehe n?chstes Kapitel), kann die Auffassung der ANOVA in der gleichen Weise erweitert werden, wie ein lineares Regressionsmodell zu einem allgemeinen linearen Modell (engl. Generalized Linear Models, glm) erweitert werden kann etc. Dies erlaubt uns also, ANOVAs auf Modelle mit nicht-normalverteilten Fehlern anzuwenden (nat?rlich muss dies der Software gesagt werden, es geht nicht automatisch davon aus). Deswegen muss man besonders Acht darauf geben, von was andere ausgehen, wenn sie diesen Term benutzen.

Hier ist ein einfaches Beispiel mit einer Standard-ANOVA (normalverteilte Fehler), in der getestet werden soll, ob Gewicht (von H?hnern) von ihrer Ern?hrung abh?ngt, wobei 'Ern?hrung' ein variabler Faktor mit vier Stufen ist:

\begin{Schunk}
\begin{Sinput}
aovresult <- aov(weight~Diet, ChickWeight)
summary(aovresult)
\end{Sinput}
\begin{Soutput}
             Df  Sum Sq Mean Sq F value   Pr(>F)    
Diet          3  155863   51954   10.81 6.43e-07 ***
Residuals   574 2758693    4806                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{Soutput}
\end{Schunk}

Wir erhalten einen p-Wert von 6.43e-07, welcher mit einem $\alpha$ Level von 0.05 h?chst signifikant ist. Somit k?nnen wir die Nullhypothese abweisen, dass die Ern?hrung keinen Einfluss auf die Response "`Gewicht"' habe. Beachte hier, dass wir keine Parametersch?tzwerte erhalten und wir keine Aussagen dar?ber machen k?nnen, welche Ern?hrung sich von welcher unterscheidet. Hierf?r gibt es zwei M?glichkeiten:

\begin{itemize}
\item Entweder wendet man den sogenannten Post-Hoc-Test an, welcher auf Unterschiede der Ern?hrungsweisen testet (Bsp. mit einem T-Test).
\item Oder man wechselt zu einer Regression, die im folgenden Kapitel genauer beschrieben wird.
\end{itemize}

Mit einem Post-Hoc-Test wendet man multiple Tests auf die gleichen Daten an. Dies kann zum Problem werden - der Gedanke des p-Werts ist die die Wahrscheinlichkeitkalkulation f?r das Betrachtet der Daten bez?glich EINER Nullhypothese. Nach einer solchen Durchf?hrung, erh?lt mal allenfalls einen  5\% Fehler bei einem $\alpha$ Level von 0.05. \marginnote{Beim Anwenden multipler Tests auf die selben Daten ben?tigt man eine Korrektur des p-Werts f?r multiples Testen.} Wenn wir jedoch multiple Tests durchf?hren, testen wir auch multiple Nullhypothesen und es ergeben sich mehr M?glichkeiten f?r die Testgr??en ein Signifikanzlevel nur durch Zufall zu erreichen. Deswegen m?ssen wir den p-Wert f?r multiples Testen korrigieren. Um hierzu mehr Informationen zu erhalten, ist Google dein bester Freund. 

\subsection{Weitere wichtige Tests}

T-Tests und ANOVA sind sehr h?ufig verwendete Tests, wobei es noch viele weitere gibt. Eine Liste mit Tests kann man beispielsweise im Wikipedia-Artikel unter diesem \href{http://en.wikipedia.org/wiki/Category:Statistical_tests}{Link} finden.


\section{Regression}

Wie schon zuvor beschrieben, bedeutet Regression nicht zwingend, dass man ein anderes statistisches Modell wie bei Hypothesentests verwendet (ANOVA und das lineare Regressionsmodell verwenden in R die gleichen Annahmen). Nichtsdestotrotz ist das Ziel einer Regression ein anderes. W?hrend Hypothesentests nur ?berpr?fen, ob die Daten mit einer Nullhypothese vereinbar sind, sucht eine Regression nach einer am besten passenden Hypothese oder Parametern (Maximum-likelihood-Sch?tzwert). Somit sucht ein Regressionsmodell nach einer Parameterkombination, die mit der h?chsten Wahrscheinlichkeit die beobachteten Daten, mit vorgegebenen Modellannahmen, ausgibt.

\subsection{Lineare Regression}

Das grundlegendste Regressionsmodell ist die lineare Regression. Hier lautet die Annahme, dass wir eine Reaktion haben, die von einem Pr?diktor wie folgt abh?ngt:

\begin{equation} \label{eq: linear regression}
y \sim a \cdot x + b + \epsilon 
\end{equation}

wobei y die Response, x der Pr?diktor ist; a ist der Parameter, wie sehr der Pr?diktor die Response beeinflusst, b ist der Schnittpunkt und $\epsilon$ ist die Zufallsvariation, welche in einer linearen Regression als normalverteilt angenommen wird.

In R wird solch eine Regression durch folgenden Befehl erreicht

\begin{Schunk}
\begin{Sinput}
fit = lm(airquality$Temp~airquality$Ozone)
summary(fit)
\end{Sinput}
\begin{Soutput}

Call:
lm(formula = airquality$Temp ~ airquality$Ozone)

Residuals:
    Min      1Q  Median      3Q     Max 
-22.147  -4.858   1.828   4.342  12.328 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)      69.41072    1.02971   67.41   <2e-16 ***
airquality$Ozone  0.20081    0.01928   10.42   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.819 on 114 degrees of freedom
  (37 observations deleted due to missingness)
Multiple R-squared:  0.4877,	Adjusted R-squared:  0.4832 
F-statistic: 108.5 on 1 and 114 DF,  p-value: < 2.2e-16
\end{Soutput}
\end{Schunk}

\begin{figure}[htbp]
\begin{center}
\begin{Schunk}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-13-1} \end{Schunk}
\caption{Luftqualit?ts Datensatz: Temperatur aufgetragen gegen Ozon. Zusammenhang durch die Regressionsgerade angegeben.}
\label{fig: LR}
\end{center}
\end{figure}

Dieser Code kann unabh?ngig davon verwendet werden, ob der Pr?diktor stetig oder kategorisch ist. Im Falle einer stetigen Variable entsteht eine Linie anhand der Daten. Im Falle einer kategorischen Variable mit n Stufen ist die erste Stufe als Referenz gesetzt (Schnittpunkt), und n-1 Faktoren entsprechen den folgenden Stufen, die den Unterschied zur Referenz beschreiben.

Die entsprechenden Parameter erscheinen in der Spalte "Estimate". Dies zeigt uns, wie sehr der Pr?diktor, in diesem Fall Ozon, die Response, hier Temperatur, beeinflusst: F?r jede Einheit Ozon mehr steigt die Temperatur um 0.208 Einheiten, mit einem Standardfehler (Konfidenzintervall) von 0.019. Abgesehen davon, wie ein Regressions-Output aussieht, lehrt uns dies etwas anderes Wichtiges: Die Tatsache, dass wir die Temperatur als Response und Ozon als Pr?diktor benutzt haben, bedeutet nicht, dass Ozon urs?chlich die Temperatur beeinflusst. \marginnote{Korrelation ist nicht Kausalit?t.}Tats?chlich ist es genau anders herum: wenn wir mehr Sonne haben, wird es w?rmer und wir haben tendenziell mehr Ozon. Regression schafft nicht, wie die meisten anderen statistischen Analysen, Kausalit?t. Es schafft Korrelation. Was wir hier ausdr?cken ist, dass wenn unsere Ozonmessungen steigen, wir ziemlich sicher davon ausgehen k?nnen, dass es auch gleichzeitig w?rmer wird. Was wiederum nicht bedeutet, dass Ozon Hitze erschafft. Korrelation ist nicht Kausalit?t.

Die Regressionsergebnisse geben uns ebenfalls einige p-Werte aus. Das sind die Ergebnisse von mehreren Hypothesentests, die automatisch f?r dich nach der Regression geschaltet sind. Beispielsweise erh?lt man einen p-Wert f?r jeden Parameter. Dieser p-Wert basiert auf einem bestimmten Typ von T-Test, wobei das vollst?ndige Modell gegen ein Modell mit auf 0 gesetzten Parametern getestet wird. Zus?tzlich gibt es noch einen weiteren p-Wert, welcher auf einer anderen Testgr??e am Ende der Regressionsausgabe beruht. Dieser testet die Nullhypothese mit allen Parametern gleich 0.

\vspace{1cm}
\begin{fullwidth}
\begin{mdframed}
    
\textbf{Pr?zisieren von verschiedenen Modellannahmen in R:} 

Response y h?ngt linear von Variable a (stetig oder kategorisch) ab

\begin{Schunk}
\begin{Sinput}
fit = lm(y~a)
summary(fit)
\end{Sinput}
\end{Schunk}

Response y h?ngt linear von zwei Variablen a und b (stetig oder kategorisch) ab, aber der Wert beider Variablen beeinflusst nicht den Effekt, welcher die andere Variable auf die Response hat (keine Interaktion)

\begin{Schunk}
\begin{Sinput}
fit = lm(y~a+b)
summary(fit)
\end{Sinput}
\end{Schunk}

Response y h?ngt linear von zwei Variablen a und b (stetig oder kategorisch) ab, aber der Wert der einen Variable beeinflusst nicht den Effekt der anderen Variable auf die Response (Interaktion)

\begin{Schunk}
\begin{Sinput}
fit = lm(y~a*b)
summary(fit)
\end{Sinput}
\end{Schunk}

Response y ist von einer Variablen a (stetig oder kategorisch) wie in $a + a^2$ abh?ngig

\begin{Schunk}
\begin{Sinput}
fit = lm(y~a + I(a^2))
summary(fit)
\end{Sinput}
\end{Schunk}

die Schreibweise I() kennzeichnet eine darauf folgende mathematische Formel. 

\end{mdframed}
\end{fullwidth}


\subsection{?berpr?fen der Annahmen}

Formal gesehen kann man jegliche Datens?tze auf lineare Modelle ?bertragen. Jedoch sind hier wie bei jeder statistischen Folgerung, die Ergebnisse (z.B. Parametersch?tzungen, p-Werte) von den getroffenen Annahmen abh?ngig. Dementsprechend ist der p-Wert, den wir erhalten, von der Annahme abh?ngig, dass die Daten auch tats?chlich mit der Formel ~\ref{eq: linear regression} ?bereinstimmen. Wenn dies nicht der Fall ist, k?nnte der p-Wert v?llig falsch sein. Somit muss man pr?fen, ob diese Annahmen auch tats?chlich erf?llt wurden.

Also was genau waren die Annahmen einer linearen Regression? Ein Problem ist, dass sich Studenten an die Annahme der Normalverteilung erinnern. Deswegen ?berpr?fen sie, ob die Response-Variable normalverteilt ist. Wenn man jedoch die Formel ~\ref{eq: linear regression} genauer betrachtet, erkennt man, dass dies nicht entscheidend ist. Wenn man die Terme in der Formel ~\ref{eq: linear regression} verschiebt,
sehen wir das, was eigentlich normalverteilt sein soll

\begin{equation} \label{eq: linear regression}
y - (a \cdot x + b ) \sim \epsilon 
\end{equation}

n?mlich der Unterschied zwischen beobachtetem Wert und den Modellvorhersagen. Diese Unterschiede werden Residuen genannt und sollten, entsprechend unserer Modellannahmen, normalverteilt sein. Um zu ?berpr?fen, ob dies wirklich der Fall ist, sollten einige Tests durchgef?hrt werden. Der einfachste Test ist das Erstellen eines Plots mit den Residuen gegen die angepassten Werte UND gegen alle Pr?diktoren im Modell. Der daraus entstehende Plot erlaubt es dann viele m?gliche Probleme zu erkennen (Fig.~\ref{fig: ResidualPatterns})

\begin{figure}[htbp]
\begin{center}
\begin{Schunk}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-18-1} \end{Schunk}
\caption{Eine Sammlung m?glicher Pattern, wenn die Residuen gegen den angepassten Wert (voreingestellt in R) oder einen Pr?diktor geplottet werden.}
\label{fig: ResidualPatterns}
\end{center}
\end{figure}

?bliche Probleme und ihre L?sungen sind  

\begin{itemize}
  \item Heteroskedastizit?t (Varianzver?nderungen) --> Ver?ndere die Response, oder verwende ein Regressionsmodell, das Heteroskedastizit?t ber?cksichtigen kann
  \item Muster in den Residuen -> Falsche Funktionsform des Regressionsmodells. Versuchen Sie, Pr?diktoren, quadratische Effekte, Interaktionen oder andere Dinge hinzuzuf?gen, die die funktionale Form ?ndern
  \item Verteilung nicht normal -> Angenommen, es liegt nicht an einem der fr?heren Probleme (kein Muster / keine Heteroskedastizit?t), kann man noch eine Variablentransformation ausprobieren oder eine Regression mit einer anderen Verteilungsannahme durchf?hren (siehe n?chsten Abschnitt)
\end{itemize}  

Es gibt weitere spezialisierte Plots, um mit der Diagnose dieser Probleme zu helfen. Diese erfolgen bei der Anwendung des Befehls plot ()


Sie erhalten grundlegende Residuendiagnosen durch Eingabe von Plot (Fit), wobei fit das angepasste Modell ist. Weitere Details zur Residuendiagnose siehe \href{http://www.statmethods.net/stats/rdiagnostics.html}{hier}.



\section{Allgemeine lineare Regressionsmodelle (glm)}

Die allgemeine Vorstellung einer linearen Regression war, dass 1) die Response stetig ist, theoretisch von - unendlich bis + unendlich, und 2) Residuen normal um die Modellvorhersagen verteilt sind. Der Grundgedanke der allgemeinen linearen Regressionsmodell-Rahmenbedingung ist, wie zuvor in dem linearen Regressionsbeispiel zu arbeiten, jedoch beide Annahmen ?ber Responsegr??en von - bis + unendlich und die Normalit?t zu lockern. Dazu m?ssen wir zwei Dinge tun

\begin{itemize}
  \item Um die Ausgabewerte in dem Bereich zu erhalten, den wir wollen, wickeln wir das lineare Modell in eine Transformationsfunktion, die die Response ins rechten Intervall zwingt (typische Intervalle sind positiv oder zwischen 0 und 1). Diese Transformation wird als Link-Funktion bezeichnet
  \item Um andere Verteilungen anzupassen, m?ssen wir dem Modell sagen, dass es etwas anderes als die Gau?sche Fehlerfunktion verwenden soll.
\end{itemize}    
   
Wir werden ?ber diese Punkte nun etwas mehr ins Detail gehen.

\subsection{Die Link-Funktion}

Wir haben gesagt, dass eine lineare Regression folgende Form annimmt

\begin{equation}
y \sim a \cdot x + b 
\end{equation}

Das hei?t, wenn x gro? wird, k?nnte y jeden Wert einnehmen, positiv oder negativ. Ein Trick, um sicherzustellen, dass alle Vorhersagen f?r y positiv sind oder innerhalb eines bestimmten Bereichs liegen, ist eine Link-Funktion der Form

\begin{equation}
y \sim f^{link}(a \cdot x + b )
\end{equation}

Jede Funktion ist m?glich, aber wie wir sp?ter sehen werden, sind typische Alternativen die Exponentialfunktion, die positive Ergebnisse garantiert, und die inverse Logit, die Bereich zwischen 0 und 1 garantiert.

\subsection{Andere Verteilungen}

Nun, das ist konzeptionell der einfache Teil, aber vielleicht ist noch nicht klar, welche Art von Distributionen neben der normalen vorhanden sind. Zwei typische Entscheidungen, die wir unten verwenden, sind die Binomial- (die Verteilung f?r das M?nzwerfen) und die Poisson-Verteilung (eine diskrete Wahrscheinlichkeitsverteilung). Es stehen viele andere M?glichkeiten zur Verf?gung. Vielleicht wird es deutlicher, wenn wir uns in den n?chsten Abschnitten zu den konkreten Beispielen bewegen.

\subsection{0/1 Daten - logistische Regression}

Logistische Regression ist die h?ufigste Analyse f?r bin?re Daten (Pr?senz / Abwesenheit, ?berlebt / tot, infiziert / nicht infiziert). Logistische Regression geht davon aus, dass die Verteilung binomial ist (M?nzwurf-Modell). Um den linearen Pr?diktor auf einer Skala zwischen 0 und 1 zu erhalten, die f?r die Binomialverteilung erforderlich ist, verwenden wir die logistische Linkfunktion (oder inverse Logit).

\vspace{1cm}
\begin{fullwidth}
\begin{mdframed}
    
\textbf{In R:} 

Hier ein Beispiel mit den Daten der Titanik-?berlebenden. Beachte, dass die Logit-Link automatisch ausgew?hlt wird, wenn in R die Binomialverteilung verwendet wird. Bei bedarf, k?nnte man diese Wahl ?berschreiben.
\begin{Schunk}
\begin{Sinput}
library(effects)
\end{Sinput}
\begin{Soutput}
Error in library(effects): there is no package called 'effects'
\end{Soutput}
\begin{Sinput}
fmt <- glm(survived ~ age + I(age^2) + I(age^3), family=binomial, data = TitanicSurvival)
\end{Sinput}
\begin{Soutput}
Error in is.data.frame(data): Objekt 'TitanicSurvival' nicht gefunden
\end{Soutput}
\begin{Sinput}
summary(fmt)
\end{Sinput}
\begin{Soutput}
Error in summary(fmt): Objekt 'fmt' nicht gefunden
\end{Soutput}
\end{Schunk}

\end{mdframed}
\end{fullwidth} 




\subsection{Z?hldaten - Poisson-Regression}

Die Poisson-Regression ist die Standard-Wahl f?r die Arbeit mit Z?hldaten, obwohl ein paar andere Optionen zur Verf?gung stehen. In der Poisson-Regression wird standardisiert eine Exponentialfunktion gew?hlt, um alle Werte positiv zu machen. Das Inverse des Exponentials ist der Log, also nennen wir das den Log-Link. Nach wie vor w?hlt R diese automatisch aus, wenn man angibt die Verteilung zu "`poissonieren"'.

\vspace{1cm}
\begin{fullwidth}
\begin{mdframed}
    
\textbf{In R:} 

Ein Beispiel hierf?r zeigt einige Daten ?ber die F?tterung von Nesthockern in Bezug auf ihre Attraktivit?t:
\begin{Schunk}
\begin{Sinput}
schnaepper <- read.csv("schnaepper.txt", sep="")
fm <- glm(stuecke ~ attrakt, family=poisson, data = schnaepper)
summary(fm)
\end{Sinput}
\begin{Soutput}

Call:
glm(formula = stuecke ~ attrakt, family = poisson, data = schnaepper)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.55377  -0.72834   0.03699   0.59093   1.54584  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  1.47459    0.19443   7.584 3.34e-14 ***
attrakt      0.14794    0.05437   2.721  0.00651 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 25.829  on 24  degrees of freedom
Residual deviance: 18.320  on 23  degrees of freedom
AIC: 115.42

Number of Fisher Scoring iterations: 4
\end{Soutput}
\end{Schunk}

\end{mdframed}
\end{fullwidth} 


\subsection{Residuen-?berpr?fungen in allgemeinen linearen Regressionsmodellen}

Residuen in allgemeinen linearen Regressionsmodellen sollten nicht normalverteilt sein, deswegen verwendet man keine Standard-Kontrollen f?r Normalit?t wie normale qq-Plots, um auf die Angemessenheit der Residuen zu ?berpr?fen. F?r nicht zu komplizierte Modelle gibt es eine M?glichkeit dieses Problem zu umgehen, indem man die sogenannten Pearsons-Residuen verwendet, die die beobachteten Unterschiede zwischen Modell und Daten durch die erwartete Varianz des Modells normiert \footnote{In R k?nnen Sie die Option Pearson in vielen Funktionen angeben, einschlie?lich der Residual()-Funktion, die Sie auf ein angepasstes Objekt anwenden k?nnen}

Ein Standardproblem in Poisson oder binomialen allgemeinen linearen Regressionsmodellen ist, dass die Varianz der Poisson- und Binomialverteilung nicht eingestellt werden kann, sondern durch den Mittelwert festgelegt wird. Dies ist ein Problem, das im normalen linearen Modell nicht auftritt, da hier der zuf?llige Teil durch eine Normalverteilung modelliert wird, die einen Parameter f?r die Varianz aufweist. Ein Problem, das sehr h?ufig in Poisson oder binomialen allgemeinen linearen Regressionsmodellen auftritt, ist eine ?berdispersion, d.h. dass die Residuen mehr Varianz, als unter dem angepassten Modell erwartet, zeigen. \marginnote{Man kann auf ?berdispersion pr?fen, indem man die angepasste Abweichung betrachtet oder einen ?berdispersionstest anwendet} Der einfachste Weg, um dies zu korrigieren, ist die Verwendung der Quasi-Poisson- und Quasibinomialmodelle, die in der allgemeinen linearen Regressionsmodell-Funktion verf?gbar sind. Diese Modelle bringen einen zus?tzlichen Parameter ein, der die Varianz des Poisson- und des binomialen allgemeinen linearen Regressionsmodells abwandelt.


\chapter{Vorhersagende Statistik - maschinelles Lernen}

Eine dritte Klasse statistischer Verfahren, die in den letzten Jahren sehr wichtig geworden sind, sind pr?diktive Verfahren, die oft maschinelle Lernalgorithmen genannt werden. Das grundlegende Ziel dieser Methoden besteht darin, Vorhersagen aus einem gegebenen Datensatz mit dem geringstm?glichen Fehler treffen zu k?nnen. Dabei verwenden sie typischerweise relativ komplizierte, oft nicht parametrische Verfahren, die typischerweise keine Berechnung von Schlussfolgerung-Ergebnisse wie die Maximum-Likelihood-Sch?tzung oder p-Werten erlauben.

Es besteht eine betr?chtliche Spannung zwischen dem eher klassischen Feld der Inferenzstatistik und dem moderneren Bereich des maschinellen Lernens. F?r klassische, inferentielle Statistiker haben maschinelle Lernmethoden die Idee des "Lernens von Daten" im Sinne des Vergleichens von Hypothesen und Daten zugunsten einfacher Prognosen aufgegeben. Ein Statistiker, der sich auf das maschinelle Lernen konzentriert, w?rde darauf antworten, dass es in vielen angewandten Problemen nichts zu lernen gibt \footnote{Typische maschinelle Lernanwendungen beinhalten die Vorhersage der Interessen der Kunden in Web-Shops, die Zuordnung funktionsreicher Satellitendaten zu Bodensignalen oder Sprache / Gesichtserkennung.}Maschinen-lernende Experten sind derzeit von Technologie-Unternehmen wie Google, Facebook und so weiter gesucht. Das Ziel ist es, einen Algorithmus zu erstellen, der in der Lage ist, bei einem komplexen Datensatz korrekt vorherzusagen. Die Unterscheidung zwischen den Zielen der Inferenzstatistik und der Vorhersagestatistik sowie die Spannungen zwischen diesen Bereichen sind in der Zusammenfassung des ?u?erst empfehlenswerten Artikels "Statistical Modeling: The Two Cultures" von \citet{Breiman-StatisticalModelingTwo-2001}nachzulesen:

\begin{quote}
Es gibt zwei Kulturen in der Verwendung der statistischen Modellierung, um Schlussfolgerungen aus Daten zu erreichen. Man geht davon aus, dass die Daten durch ein gegebenes stochastisches Datenmodell erzeugt werden. Die andere verwendet algorithmische Modelle und behandelt den Datenmechanismus als unbekannt. Die statistische Gemeinschaft hat sich der nahezu ausschlie?lichen Nutzung von Datenmodellen verschrieben. Dieses Engagement hat zu irrelevanten Theorien, fragw?rdigen Schlussfolgerungen gef?hrt und hat die Statistiker daran gehindert, an einer Vielzahl interessanter aktueller Probleme zu arbeiten. Die algorithmische Modellierung, sowohl in Theorie und Praxis, hat sich schnell in Bereichen au?erhalb der Statistik entwickelt. Es kann sowohl auf gro?en komplexen Datens?tzen als auch als genauere und lehrreichere Alternative zur Datenmodellierung auf kleineren Datens?tzen verwendet werden. Wenn es unser Ziel ist, Daten zu nutzen, um Probleme zu l?sen, dann m?ssen wir uns von der exklusiven Abh?ngigkeit von Datenmodellen entfernen und ein breiteres Spektrum an Tools annehmen.
\end{quote}


Ich habe dieses kurze Kapitel wegen der Bedeutung der pr?diktiven Methoden in der modernen Statistik aufgenommen. Eine detaillierte Erl?uterung der Methoden des maschinellen Lernens ist jedoch jenseits dieser Einf?hrung. Bei bestehendem Interesse mehr ?ber pr?diktive Methoden zu lernen, w?rde ich empfehlen, mit dem Lehrbuch von \citet{James-IntroductiontoStatistical-2013}zu beginnen, das ich auch am Ende dieses einf?hrenden Skripts f?r die weitere Lesung empfehle.

\chapter{Versuchsplanung}\label{cha: design of experiments}

Kommen wir zur?ck zu einem der ersten Punkt in diesem Skript: die Daten. Wenn wir selbst Daten sammeln m?ssen, m?ssen wir eine Reihe von Fragen beantworten. Welche Variablen sollten wir sammeln? Bei welchen Werten sollten wir Daten sammeln? Und wie viele Replikate brauchen wir?


\section{Auswahl der Variablen}

In einem praxisbezogenem Settings sind wir typischerweise daran interessiert, wie eine Response von einer Anzahl von Pr?diktor-Variablen beeinflusst wird. Es ist klar, dass wir sowohl die Response als auch die Pr?diktoren unseren Interesses durch einige dieser Pr?diktorwerte messen m?ssen, um etwas ?ber die Wirkung der Pr?diktoren zu sagen. \marginnote{Korrelation ist keine Kausalit?t.}Wenn wir nur wissen wollten, ob es eine Korrelation zwischen Pr?diktoren und Response gibt, w?re unsere Variablenliste zu diesem Zeitpunkt vollst?ndig. Normalerweise wollen wir aber nicht nur wissen, ob es eine Korrelation gibt, sondern auch, ob wir mit einiger Sicherheit sagen k?nnen, dass diese Korrelation kausal ist. Wenn wir diesen Anspruch geltend machen wollen, m?ssen wir ausschlie?en, dass es auch gegens?tzliche Faktoren gibt, die auch als St?rvariablen bezeichnet werden.

\subsection{Was ist eine St?rvariable?}

Man stelle sich vor, wir sind an einer Response A interessiert, und wir haben angenommen, dass A ~ B. Man stelle sich vor, dass es eine zweite Pr?diktorvariable C gibt, die einen Einfluss auf A hat, an der wir aber f?r den Zweck der betrachteten Frage nicht interessiert sind. Eine solche Variable, die f?r die Frage nicht von Interesse ist, wird auch als "Fremdvariablen" bezeichnet.\marginnote{Eine Fremdvariable ist eine Variable, die die Response beeinflussen kann, ist aber f?r den Experimentator nicht von Interesse.}So haben wir auch A ~ C, aber wir sind nicht an dieser Beziehung interessiert. Wenn wir nun Daten erfassen und nicht C messen, ist es normalerweise kein Problem, solange C mit B unkorreliert ist - es k?nnte ein bisschen mehr Variabilit?t in der Response erzeugen, aber im Gro?en und Ganzen sollte der Effekt von C durchschnittlich sein und wir sollten die Auswirkung von B noch feststellen k?nnen.

\begin{figure}[]
\begin{center}
\includegraphics[width = 6cm]{Confounding}
\caption{Diagramm, das eine St?rvariable darstellt. Eine wichtige Voraussetzung f?r einen St?rfaktor ist, dass die Variable sowohl mit der Response korreliert als auch mit den Pr?diktorvariablen, die unsere urspr?ngliche Hypothese bilden. Wenn die zweite Verbindung nicht vorhanden ist, ist die Variable nicht st?rend und kann ignoriert werden.}
\label{fig: Confounding}
\end{center}
\end{figure}

Das Problem des St?rfaktors tritt auf, wenn die Fremdvariable C aus irgendeinem Grund mit der zu betrachtenden Pr?diktorvariable B korreliert. \marginnote{Eine St?rvariable ist eine externe Variable, die sowohl mit der Response als auch mit einer zu betrachtenden Pr?diktorvariable korreliert.}In dem Fall, wenn wir nur B messen, sehen wir die Auswirkungen von B und C. In diesem Fall schreiben wir die Auswirkung von C auf A f?lschlicherweise der Auswirkung von B auf A zu. \marginnote{Eine Scheinkorrelation ist eine Korrelation, die durch eine St?rvariable verursacht wird.} Eine Korrelation, die durch eine nicht gemessene St?rvariable verursacht wird, wird als Scheinkorrelation bezeichnet.

\subsection{Was macht man mit St?rvariablen}

Wenn wir denken, es gibt einen Faktor, der gest?rt werden k?nnte, haben wir grunds?tzlich drei Optionen

\begin{enumerate}
\item Am besten: steuern Sie den Wert dieser Faktoren. Entweder durch Fixieren des Wertes (bevorzugt, wenn wir nicht an diesem Faktor interessiert sind), oder durch ?ndern des Wertes in einer kontrollierten Weise (siehe unten).
\item Zweitens: zuf?llig anordnen und messen
\item Drittens: Nur zuf?llig anordnen oder nur messen
\end{enumerate}

Die Randomisierung bedeutet, dass wir versuchen, sicherzustellen, dass der St?rfaktor nicht systematisch mit der Variablen von Interesse korreliert (kann jedoch potentiell noch immer Probleme mit Wechselwirkungen und nichtlinearen Beziehungen hervorrufen).


Das Messen\marginnote{Variablen, die wir einbeziehen, aber f?r uns nicht interessant sind, werden oft als St?rungsvariablen bezeichnet.} erlaubt es uns, die Auswirkungen in einer statistischen Analyse zu ber?cksichtigen, aber es kostet Kraft (siehe unten) und wir k?nnen nicht alles messen.
\section{Definition und Bias von Variablen}

Ein h?ufiger Fehler bei diesem Schritt des Versuchsentwurfs ist es, die Variablendefinition und die Messungen f?r selbstverst?ndlich zu erachten und sich eher mit Entscheidungen ?ber Wiederholungen und so weiter auseinander zu setzen. Der fehlende Schritt ist jedoch, ?ber die folgenden zwei Fragen nachzudenken. \marginnote{Die Betrachtung dieser beiden Fragen wird oft als Konstruktvalidit?t bezeichnet.}

\begin{enumerate}
  \item Messen meine Variablen, was ich messen m?chte
  \item Was ist der erwartete statistische (stochastische) Fehler in meinen Messungen, und was ist der m?gliche systematische Fehler in meinen Messungen
\end{enumerate}

\begin{figure}[]
\begin{center}
\includegraphics[width = 10cm]{RandomizedBlockDesign}
\caption{Illustration eines randomisierten Blockdesigns, der wohl am h?ufigsten verwendeten Anordnung bei (Beobachtungs)-Experimente zur Randomisierung der Auswirkung unbekannter und nicht gemessener verwandter Variablen. Die Idee dieses Entwurfs ist, dass die unbekannten Variablen wahrscheinlich im Raum korrelieren. Indem wir alle experimentell ver?ndernden Variablen zu einem Block zusammenfassen, vermeiden wir, dass sie von den unbekannten r?umlichen Variablen gest?rt werden k?nnen.}
\label{fig: RandomizedBlockDesign}
\end{center}
\end{figure}


Das erste Punkt mag ein wenig seltsam erscheinen, weil man denken w?rde, man wisse was man misst. Doch in vielen F?llen der ?kologischen Statistik und dar?ber hinaus, messen wir nicht direkt die Variable, an der wir interessiert sind, sondern einen Stellvertreter. Zum Beispiel, wollen wir die Temperatur an einer bestimmten Stelle wissen, und verwenden dabei die Temperatur von einer Wetterstation 5 km entfernt. Oder wir wollen die funktionale Vielfalt untersuchen, aber wie k?nnen wir dies in Form von Variablen ausdr?cken, die wir im Feld messen?

Die zweite Frage bezieht sich darauf, wie sehr sich zwei Messungen voneinander unterscheiden w?rden, wenn wir sie wiederholt (stochastisch) durchf?hren und wie viele Messungen systematisch ausfallen k?nnten (z.B. weil eine Methode oder ein Instrument systematisch falsch ist oder weil der Mensch bestimmte Einfl?sse (Bias) zeigt).


\section{Auswahl der Werte f?r die unabh?ngigen (Pr?diktor-) Variablen}

Wenn wir entschieden haben, welche Variablen zu messen sind / variieren, m?ssen wir uns f?r die Gr??en entscheiden, an denen wir sie messen wollen.

In\marginnote{Die experimentelle Einheit ist die Einheit, die einer bestimmten Variablenkombination (z.B. Behandlung oder Kontrolle) zugewiesen werden kann. Beispiel: eine einzelne Pflanze oder ein Topf.} In einer experimentellen Studie ver?ndern wir in der Regel Variablen systematisch f?r eine bestimmte Einheit, z.B. eine Pflanze, ein Topf oder ein Grundst?ck. Diese Einheit hei?t die experimentelle Einheit. Auch Beobachtungsstudien haben experimentelle Einheiten (die Einheiten, f?r die Messungen durchgef?hrt werden), aber es ist meist nicht m?glich, die Variablen vollst?ndig zu kontrollieren. Allerdings hat man in der Regel die M?glichkeit, bestimmte Selektionen vorzunehmen. Auch in Beobachtungsstudien ist es entscheidend, eine ausreichende Variation der Pr?diktorvariablen ?ber die experimentellen Einheiten zu gew?hrleisten, um eine aussagekr?ftige statistische Analyse zu erm?glichen.

Hier sind ein paar Punkte, die zu beachten sind

\subsection{Variieren aller Variablen unabh?ngig voneinander}

Ein ?bliches Problem in der Praxis ist, dass wir zwei Variablen haben, ihre Werte sich jedoch in einer korrelierten Weise ?ndern. Man stelle sich vor, wir testen auf das Vorhandensein einer Art, aber wir haben nur warme trockene und kalte nasse Stellen. Wir behaupten die beiden Variablen seien kollinear. In diesem Fall wissen wir nicht, ob der beobachtete Effekt auf Temperatur oder Wasserverf?gbarkeit zur?ckzuf?hren ist. Das Fazit: Wenn man zwei Effekte trennen m?chte, darf die Korrelation zwischen ihnen nicht ?bereinstimmend sein - idealerweise w?re es Null oder so niedrig wie m?glich. 

\subsection{Interaktionen}

Um Wechselwirkungen zwischen Variablen erkennen zu k?nnen, gen?gt es nicht, alle zu ver?ndern, sondern es bedarf bestimmter Kombinationen. Das Schlagwort hier ist (fraktionierte) faktorielle Versuchsplanung. Google wird hier weiterhelfen.

\subsection{Nichtlineare Effekte}

Die Verbindung von zwei Punkten ist eine Linie. Wenn man herausfinden m?chte, ob die Response auf eine Variable nichtlinear ist, ben?tigt man daher mehr als zwei Werte f?r jede Variable. 


\section{Wie viele Replikate?}

Wir haben bereits erw?hnt, dass das Signifikanzniveau $\alpha$ die Wahrscheinlichkeit ist, falsch Positives zu finden. Dies wird als Typ-I-Fehler bezeichnet. Es gibt einen weiteren Fehler, den man machen kann: es wird keine Signifikanz f?r einen wahren Effekt erkannt. Dies wird als Typ-II-Fehler bezeichnet und die Wahrscheinlichkeit, einen Effekt zu finden, wird als Testst?rke (engl. power) bezeichnet. \marginnote{Testst?rke ist die Wahrscheinlichkeit, Signifikanz f?r einen Effekt zu finden, wenn es welche gibt}. F?r statistische Standardverfahren kann die St?rke berechnet werden. Man muss f?r jede einzelne Methode nachsehen, aber im Allgemeinen geht man davon aus, dass 

\begin{enumerate}
\item die Testst?rke mit zunehmender Einflussgr??e steigt 
\item die Testst?rke mit zunehmender Variabilit?t in der Response sinkt
\end{enumerate}

Das bedeutet, dass, im Gegensatz zum festgelegten Typ-I-Fehler, die Berechnung der Testst?rke Kenntnisse ?ber den erwarteten Effekt und die Variabilit?t erfordert. Das klingt nicht gut, jedoch kann man in den meisten F?llen aus Erfahrung absch?tzen, wie viel Variation es geben wird, und in den meisten F?llen wei? man auch, wie gro? der Effekt mindestens sein muss, um relevant zu sein. Danach kann man berechnen, wie viele Proben man ben?tigt.

\newpage
\begin{mdframed}
    
\textbf{Checkliste f?r die Versuchsplanung}

\begin{description}

\item[( )] Eindeutige, logisch einheitliche Frage? Schreib es auf. Lesen des Kapitels ?ber g?ltige / gute wissenschaftliche Fragen in den Vorlesungsunterlagen

\item[( )] Stelle sicher, dass alle Fragen der Richtigkeit, die in den Haupt-Vorlesungsunterlagen besprochen wurden, gelesen und ber?cksichtigt haben. Gehen Sie durch die Checkliste Richtigkeit am Ende des Abschnitts in den Haupt-Vorlesungsunterlagen.

\item[( )] Entwerfe einen Versuchsaufbau

  \begin{description}

  \item[( )] Ver?ndere die Variablen, die zu messen sind, um die Fragen beantworten zu k?nnen. Entscheide, ob man an linearen Hauptauswirkungen oder auch an nichtlinearen Effekten oder Interaktionen interessiert ist.
  
  \item[( )] Schreibe potenzielle St?rvariablen auf. Entscheide, ob sie besser kontrolliert, randomisiert oder gemessen werden sollten? Sind diese sicher st?rend (korreliert mit Response UND einem oder mehreren der Pr?diktoren)
  
  \item[( )] Definiere die zu testende statistische Hypothese, einschlie?lich der St?rgr??e. Schreibe es auf, wie in $height  \sim age + soil * precipitation + precipitation^2$. 
  
  \item[( )] W?hle aus, wie die Variablen im Experiment variiert werden. Ziehe die Verwendung von Software daf?r in Betracht, z.B. f?r fraktielle faktorielle Versuchsplanungen (in Beobachtungsstudien hat man manchmal begrenzte Kontrolle, aber man kann vielleicht sch?tzen, welche Variablenkombinationen beobachtet werden).
  
  \item[( )] Blocking - versuche, verschiedene Behandlungen / verschiedenste Kombinationen zusammen zu gruppieren. Das Ziel ist, dass unbekannte / nicht gemessene Variablen nicht mit experimentellen Variablen korrelieren (siehe Pseudoreplikation)
  
  \item[( )] Bestimme die Anzahl der Replikate. Mache eine Vermutung f?r Effektgr??e und Variabilit?t der Daten, und berechne oder errate die Anzahl der notwendigen Wiederholungen, um gen?gend Testst?rke zu erhalten. Was gen?gend bedeutet, h?ngt vom Sachgebiet ab, aber ich w?rde behaupten, dass du eine hohe Chance haben m?chtest, einen Effekt zu sehen, wenn einer da ist, also w?re eine Testst?rke von $>80\%$ gut.
  
  \end{description}
  
\item[( )] Versuchsaufbau pr?fen
  
  \begin{description}
  
  \item[( )] Spiele die Abl?ufe des Datenerhalts durch: simuliere es im Geiste oder in R, mache einige Daten, schreibe es auf. Scheint alles in Ordnung?
  
  \item[( )] Spiele die Abl?ufe der Datenanalyse durch. Welche Methode? Kannst du deine Frage beantworten? Mach eine Testst?rken-Analyse!

  \end{description}


\item[( )] ?berarbeite alles, wenn n?tig

\end{description}

\end{mdframed}


\chapter{Wissenswertes und weiterf?hrende Lekt?ren}

\section{Reproduzierbarkeit und gute wissenschaftliche Vorgehensweise}

Reproduzierbarkeit bedeutet, dass jeder Schritt der Analyse wiederholbar ist. Die Erfahrung zeigt, dass es nicht so trivial ist, wie man denkt, die Reproduzierbarkeit zu gew?hrleisten. Hier einige Hinweise, wie man Datenanalyse reproduzierbar machen kann

\begin{itemize}

\item{Sobald man Rohdaten produziert hat, ?ndert man es NIE. Man speichert sie an einem Speicherort, erstellt eine Sicherung und ber?hrt sie niemals erneut}

\item{In der Regel muss man einige Aufwertungen, Umbenennung etc. vor der Datenanalyse tun. Wenn m?glich, machen man dies durch ein Skript (z. B. R, Python, perl). Man speichert das Skript mit der Analyse.}

\item{Verwende ein Versionskontrollsystem f?r den Code und notiere f?r jede Ausgabe die Revisionsnummer, mit der die Ausgabe erstellt wurde.}

\item{Wenn die Analyse durchgef?hrt wird, speichere die random-seed und die Einstellungen des Computers, um die Reproduzierbarkeit sicherzustellen. In R ist der einfachste Weg dies zu tun, die random-seed auf random.seed(123) zu setzen und die Ergebnisse von sessionInfo(), welche die Versionsnummern aller verwendeten Pakete enth?lt, zu speichern}

\item{Denke dar?ber nach, den Code in einer Reporting-Umgebung wie z.B. Rmd oder sweave auszuf?hren}


%\footnote{Siehe auch die R-Task-Ansicht ?ber \href{https://cran.r-project.org/web/views/ReproducibleResearch.html}{reproduzierbare Forschung}

\end{itemize}

\section{Wie man mehr ?ber die Statistik lernen kann}\label{sec: further readings}


\begin{itemize}

\item Um dieses einf?hrende Skript zu vervollst?ndigen, w?rde ich empfehlen die \href{https://github.com/florianhartig/ResearchSkills/tree/master/Labs/Statistics}{Praxis des Skripts} durchzugehen.

\item Wenn man ein weiteres praktisches Lehrbuch f?r Anf?nger m?chte, empfehle ich \citet{Dormann-ParametrischeStatistik-2013} f?r Deutschsprachige (eBook Kostenlos f?r Studenten aus Freiburg, kontaktieren Sie mich) und \citet{Gotelli-PrimerEcologicalStatistics-2004} f?r Englischsprechende. 

\item F?r die technisch etwas Ehrgeizigeren (es ist immer noch sehr elementar), empfehle ich \citet{James-IntroductiontoStatistical-2013}. Man kann die PDF kostenlos herunterladen und es gibt ein MOOC f?r das Buch mit Vortr?gen und ?bungen.

\item Weitere Hilfe und Hinweise kann man in der Statistik-Hilfe unserer Abteilung  \href{http://biometry.github.io/APES/}{hier} finden; insbesondere die Empfehlungen zu R-Skripten und statistischen Lehrb?chern.

\end{itemize}


\bibliographystyle{chicago}
\bibliography{/Users/Florian/Home/Bibliography/Databases/flo}


\addtocontents{toc}{\protect\setcounter{tocdepth}{0}}

\begin{appendices}

\chapter{R und Rstudio}

R selbst ist ein Befehlszeilenprogramm, d.h. man kommuniziert damit ?ber schriftliche Befehle in der R-Konsole. Im Prinzip kann man also den R-Code in einem Editor (auch Microsoft Word) schreiben und f?gt es dann in die R-Konsole ein.

F?r die t?gliche Arbeit ist dies jedoch nicht sehr praktisch. Man m?chte ein Programm, das die Kern-R-Konsole und den Editor kombiniert, und vielleicht einige andere Optionen beinhaltet, wie z.B. die M?glichkeit graphische Ausgaben aus R, eingelesene Daten etc. anzuzeigen. 


R bietet einen einfachen Editor, der grundlegende Funktionen dieser Art zur Verf?gung stellt (beachte, dass es auf einem Mac etwas anders aussieht als die Windows-Version, die wir hier zeigen). Dieser Editor hei?t RGui. Um das RGui zu starten, startet man das Programm R aus den Programmen in Windows. Betrachte das sich ?ffnende Fenster und gebe 2 + 2 im Hauptfenster ein. Nach dr?cken der Enter-Taste, wird folgendes zu sehen sein:

\begin{figure}[]
\begin{center}
\includegraphics[width = 6cm]{rgui1.png}
\caption{Eine einfache Rechnung in RGui tippen}
\label{fig: Rgui1}
\end{center}
\end{figure}


Das Fenster, das man hier sieht, wird die R-Konsole genannt. Durch die Konsole interagiert man mit dem Kern-R-Programm, das die gesamte Kommunikation ausf?hrt.

Nun schreiben wir etwas anderes: R hat einige Standarddatens?tze, die automatisch geladen werden. Wir werden den airmiles-Datensatz verwenden, der die Anzahl der vergebenen Luftmeilen anzeigt. Wir werden nun kurz erl?utern, wie man ein Diagramm mit diesem Datensatz erstellt. Tippe:

\begin{Schunk}
\begin{Sinput}
plot(airmiles, col = 4)
\end{Sinput}
\end{Schunk}

Das Ergebnis sollte wie folgt aussehen Fig.~\ref{fig: Rgui2}:

\begin{figure}[]
\begin{center}
\includegraphics[width = 6cm]{rgui2.png}
\caption{Ein Graph erstellt mit RGui}
\label{fig: Rgui2}
\end{center}
\end{figure}

Wie man erkennen kann, ?ffnet dies anscheinend ein neues Fenster (eine Grafik-Ausgabe) und plottet die Luft-Meilen gegen die Zeit. Wir werden diskutieren, warum und wie das funktioniert. Bevor man sich nun an RGui gew?hnt, sehen wir uns zuerst RStudio an, ein alternatives Programm, um mit R zu interagieren.

\section{Der Rstudio Editor}
 
RStudio bietet grunds?tzlich die gleichen Funktionen wie das RGui, aber man kann vieles einfacher machen oder bequemer handhaben. So sieht es aus:

\begin{figure}[]
\begin{center}
\includegraphics[width = 9cm]{rst_interface.png}
\caption{Der RStudio Editor, der wohl beliebteste Editor f?r R}
\label{fig: Rstudio}
\end{center}
\end{figure}


\paragraph{Konsole:} Die Konsole, die wir bereits gesehen haben, befindet sich im linken unteren Bereich. Man kann nachweisen, dass sie sich gleich verh?lt, indem man die gleichen Befehle wie zuvor eingibt, d.h. 2 + 2, oder das Diagramm erneut grafisch darstellt.

\paragraph{Editor:} ?ber der Konsole (oben links) werden r Skriptdateien angezeigt und k?nnen im Editor ge?ndert werden. Die Idee einer Skriptdatei ist, dass man alle Befehle sammelt, die man an die Konsole in einer Datei sendet, sodass man sie sp?ter erneut ausf?hren kann.  

Ein typisches Skript kann so aussehen:

\begin{Schunk}
\begin{Sinput}
# the hash means this is treated as a comment
# this file is written by FH, 25.10.13

rm(list=ls(all=TRUE))  # this command means all variables in the memory are erase

# load some data

# do some plots
\end{Sinput}
\end{Schunk}

Um einen Teil des Skripts an die Konsole zu senden, k?nnen Sie den run-Button am oberen rechten Rand des Editorfensters verwenden. F?r alles, was wir von nun an tun, w?rde ich dringend empfehlen, es in das Skript zu schreiben und es dann von dort aus an die Konsole zu senden.

\chapter{Verarbeitung von Daten in R}
\label{HandlingDataInR}

\section{Variablen}

Wer hat jemals mit einer Programmiersprache gearbeitet? In einer Programmiersprache werden die Daten in Variablen / Objekten gespeichert. So weisen wir der Variablen "VariableX" das Wort "test" zu,

\begin{Schunk}
\begin{Sinput}
VariableX = "test"
\end{Sinput}
\end{Schunk}

Ich kann jetzt auf die Variable zugreifen, indem ich seinen Namen in der Konsole eingebe und es wird den Wert ausgeben, den es gespeichert hat.
\begin{Schunk}
\begin{Sinput}
VariableX
\end{Sinput}
\begin{Soutput}
[1] "test"
\end{Soutput}
\end{Schunk}

Wir k?nnen alle Variablen, die wir in der globalen Umgebung oder in R angegeben haben, in der oberen rechten Ecke oder in RStudio sehen. Wie man sieht haben wir hier die Variable "VariableX" zusammen mit ihrem Wert.


\begin{figure}[]
\begin{center}
\includegraphics[width = 6cm]{rst_globenv.png}
\caption{Die globale Umgebung wird in der oberen rechten Ecke des R Studio-Editors angezeigt.}
\label{fig: Rstudio}
\end{center}
\end{figure}

\section{Datentypen und Strukturen}

Eine Variable kann verschiedene Dinge speichern: eine Zahl, ein Wort, eine Liste oder eine ganze Datenmenge.

Der einfachste Fall sind Variablen, die nur einen **einzigen Wert** enthalten. Hier ist die Frage, welche Art von Werten die Variable enth?lt. Die verschiedenen Datentypen, die ein einzelner Wert haben kann, hei?en die **atomaren Typen** (atomic types) - sie entsprechen den grundlegenden Datentypen in R. Wichtige Atom-typen sind:

- boolean (TRUE / FALSE)
- ganzzahlig (1, 2, 3, 5)
- numerisch (1.1, 2.5, 3.456)
- Faktor ("rot", "gr?n", "blau")
- Subjekt ("ein Wort", "ein weiteres Wort")

Wenn wir eine Sammlung von mehreren "atomic types" haben, sprechen wir von einer Datenstruktur oder einem Objekt (es gibt einen Unterschied, der hier aber keine Rolle spielt). Wichtige Beispiele hierf?r sind:

- **Vektor** (Eine Reihe der gleichen 'Atom-typen', z.B. [1,2,3,4,5] )
- **Liste** (Im Grunde wie ein Vektor, kann aber verschiedene Typen enthalten, Bsp. [1, "rot", FALSE] )
- **data.frame** (Eine Liste von Vektoren, dies ist das Standardformat f?r Daten in R. Man stellt sich dies wie eine Tabelle vor - jede Spalte ist ein Vektor und kann einen anderen Typ haben)

Eine vollst?ndige Liste der Datentypen finden Sie hier http://www.statmethods.net/input/datatypes.html 
 
\subsection{Pr?fung von Datentypen und Strukturen}

Besonders nach dem Einlesen Ihrer Daten ist es wichtig zu pr?fen, welchen Typ die Daten haben. Die Funktionen in R reagieren je nach Atom-Typ unterschiedlich.

Wenn man wissen will, welchen Typ oder Struktur eine Variable hat, verwendet man den str-Befehl:

\begin{Schunk}
\begin{Sinput}
str(object)
\end{Sinput}
\end{Schunk}

Um eine Zusammenfassung Ihrer Struktur (z. B. Mittelwert pro Spalte; was genau zusammengefasst wird, ist abh?ngig von Datenstruktur und Typ) zu erhalten, verwenden Sie:

\begin{Schunk}
\begin{Sinput}
summary(object)
\end{Sinput}
\end{Schunk}

Um eine automatischen Plot zu erstellen (R wird selbst entscheiden, welcher am meisten f?r diese Struktur / Typ geeignet ist), tippt man:

\begin{Schunk}
\begin{Sinput}
plot(object)
\end{Sinput}
\end{Schunk}

Probiere dies mit dem Objekt Luftqualit?t.

\subsection{Zugriff auf Spalten, Zeilen und Elemente in einem Datenframe oder einer Matrix}

Wie bereits erw?hnt, ist die h?ufigste Struktur in R der Datenframe. Grunds?tzlich werden Spalten als eine Liste von Vektoren gespeichert, so dass jede Spalte ein anderer Datentyp sein kann.

Man kann Spalten auf verschiedenste Weisen ausw?hlen:

- Nach Name:
\begin{Schunk}
\begin{Sinput}
airquality$Ozone
\end{Sinput}
\end{Schunk}

- Nach Spaltenindex: 

\begin{Schunk}
\begin{Sinput}
airquality[,1]
\end{Sinput}
\end{Schunk}

Zu beachten sei hier, dass die erste Spalte durch [,1] ausgedr?ckt wird. Die erste Reihe erh?lt man durch [1,].

\section{Daten ausw?hlen}

Die letzte Art des Datenzugriffs ist ein Beispiel f?r das "Slicen". Slicing ist eine sehr leistungsf?hige Technik, die in den meisten wissenschaftlichen Programmiersprachen verf?gbar ist. Das bedeutet, dass Sie auf Ihre Daten zugreifen k?nnen, indem Sie Spalten, Zeilen oder bestimmte Elemente eingeben. Schauen Sie sich die folgenden Befehle an (Erl?uterung immer unten):

\begin{Schunk}
\begin{Sinput}
airquality[,1:2]
\end{Sinput}
\end{Schunk}

verschafft die ersten Spalten 1 und 2.


\begin{Schunk}
\begin{Sinput}
airquality[4:6,1]]
\end{Sinput}
\end{Schunk}

verschafft die Reihen 4 bis 6 in Spalte 1


\begin{Schunk}
\begin{Sinput}
airquality[c(1,2,3,4,7,8),1]
\end{Sinput}
\end{Schunk}

verschafft die Reihen 1,2,3,4,7,8 in Spalte 1. 

So k?nnen wir eine beliebige Kombination von gew?nschten Elementen sehr bequem aus dem Datenframe ausw?hlen. Noch einfacher ist das Erstellen von Selektionen.


\begin{Schunk}
\begin{Sinput}
1:10
\end{Sinput}
\end{Schunk}

verschafft uns die Werte von 1 bis 10

\begin{Schunk}
\begin{Sinput}
c(1,5,6)
\end{Sinput}
\end{Schunk}

Die c() - Funktion kombiniert Werte in einem Vektor (f?r das Slicen ist es notwendig die Werte in einem Vektor zu haben)

\begin{Schunk}
\begin{Sinput}
c(1,5,6)
\end{Sinput}
\end{Schunk}

Wir k?nnen aber auch Selektionen mit logischen Operatoren erzeugen

\begin{Schunk}
\begin{Sinput}
airquality$Temp > 80
\end{Sinput}
\end{Schunk}

Erstellt einen Vektor mit True auf allen Temperaturwerten, die >80 sind. Ich kann diesen speichern und f?r eine Selektion, oder auch sofort verwenden


\begin{Schunk}
\begin{Sinput}
airquality[airquality$Temp > 80 , ]
\end{Sinput}
\end{Schunk}

W?hlt alle Zeilen mit einer Temperatur >80 aus.


\section{Laden von Daten in R}

Bisher hatten wir die Daten schon im R Programm. Nun werden wir demonstrieren, wie einige Daten geladen werden (wir verwenden die airquality.txt-Datei, die zur Verf?gung gestellt wird)

Es gibt grunds?tzlich zwei M?glichkeiten Daten zu laden

- mit RStudio (Punkt und Klick) - gehe zu Environment (oben rechts), importiere den Datensatz und folge den Anweisungen

- aus dem Skript mit dem Befehl read.table ()

Das funktioniert so


\begin{Schunk}
\begin{Sinput}
data = read.table("airquality.txt", header = T)
\end{Sinput}
\end{Schunk}

In diesem Fall funktioniert es gut, weil ich die Daten auf die einfachste Weise vorbereitet habe. Wenn man andere Datenformate (Kommas, Semikolons, ?berschriften / keine ?berschriften) hat, befragt man die Hilfe-Option mit dem Befehl read.table. Siehe auch http://www.statmethods.net/input/importingdata.html f?r weitere Optionen, z.B. Excel oder Datenbankimport.

\subsection{?berpr?fen der Daten}

?berpr?fe nach dem Laden der Daten immer, ob das Datenformat korrekt ist

\begin{Schunk}
\begin{Sinput}
str(data)
\end{Sinput}
\begin{Soutput}
function (..., list = character(), package = NULL, lib.loc = NULL, 
    verbose = getOption("verbose"), envir = .GlobalEnv)  
\end{Soutput}
\end{Schunk}

Hier sieht man den Atom-Typ jeder S?ule. Stelle sicher, dass es dem entspricht, was man m?chte (manchmal wird numerisch als Faktor eingelesen , oder umgekehrt). Wenn eine Spalte den falschen Typ haben w?rde, m?ssen wir das manuell ?ndern durch:

\begin{Schunk}
\begin{Sinput}
as.factor(x)
\end{Sinput}
\end{Schunk}
or 
\begin{Schunk}
\begin{Sinput}
as.numeric(x)
\end{Sinput}
\end{Schunk}


Hinweis: Diese Datei ist bereits in R enthalten. Wenn man es nicht schafft den Datensatz zu laden, kann man trotzdem fortfahren.

\chapter{Plot-Befehle in R}

Davor einige wichtige Hinweise

\begin{itemize}
\item \href{http://rgraphgallery.blogspot.de/search/label/3%20vartiable%20plots}{hier}
\item Sehr hilfreich, der \href{http://shiny.stat.ubc.ca/r-graph-catalog/#}{R Graphenkatalog}
\item \href{http://rgm3.lab.nig.ac.jp/RGM/R_image_list?page=2282&init=true}{R Graphik-Handbuch}
\item \href{http://www.statmethods.net/graphs/line.html}{QuickR}
\end{itemize}


\marginnote{Ein ?berblick ?ber die Farben in R \href{here}{http://research.stowers-institute.org/efg/R/Color/Chart/ }}

\begin{Schunk}
\begin{Sinput}
plot(airquality$Ozone, airquality$Temp)
\end{Sinput}


{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-42-1} 

}

\end{Schunk}


\begin{Schunk}
\begin{Sinput}
hist(airquality$Ozone, breaks = 30, col = "darkred", xlab = "Ozone ")
\end{Sinput}


{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-43-1} 

}

\end{Schunk}


\begin{Schunk}
\begin{Sinput}
plot(airquality)
\end{Sinput}


{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-44-1} 

}

\end{Schunk}

pairs(airquality)


Einfaches Balkendiagramm

\begin{Schunk}
\begin{Sinput}
counts <- table(mtcars$gear)
barplot(counts, main="Car Distribution", 
   xlab="Number of Gears")
\end{Sinput}


{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-45-1} 

}

\end{Schunk}

Gruppiertes Balkendiagramm

\begin{Schunk}
\begin{Sinput}
counts <- table(mtcars$vs, mtcars$gear)
barplot(counts, main="Car Distribution by Gears and VS",
  xlab="Number of Gears", col=c("darkblue","red"),
  legend = rownames(counts), beside=TRUE)
\end{Sinput}


{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-46-1} 

}

\end{Schunk}



\begin{Schunk}
\begin{Sinput}
boxplot(mpg~cyl,data=mtcars, main="Car Milage Data", 
   xlab="Number of Cylinders", ylab="Miles Per Gallon")
\end{Sinput}


{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-47-1} 

}

\end{Schunk}

Gekerbter Boxplot des Zahnwachstums gegen 2 gekreuzte Faktoren aufgetragen
Boxen f?r eine leichtere Interpretation eingef?rbt

\begin{Schunk}
\begin{Sinput}
boxplot(len~supp*dose, data=ToothGrowth, notch=TRUE, 
  col=(c("gold","darkgreen")),
  main="Tooth Growth", xlab="Suppliment and Dose")
\end{Sinput}
\begin{Soutput}
Warning in bxp(structure(list(stats = structure(c(8.2, 9.7, 12.25, 16.5, : some notches went outside hinges ('box'): maybe set notch=FALSE
\end{Soutput}


{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-48-1} 

}

\end{Schunk}

%See http://www.statmethods.net/graphs/index.html 


Korrelations-Heatmap. Die Heatmap visualisiert die Korrelation zwischen Variablen. Eine praktische Eigenschaft dieser Funktion ist, dass Variablen neu angeordnet werden k?nnen, so dass eng korrelierte Variablen nahe beieinander liegen. Dies ist oft n?tzlich, wenn man nicht korrelierte Variablen f?r eine Analyse ausw?hlen m?chte

\begin{Schunk}
\begin{Sinput}
round(Ca <- cor(attitude), 2)
\end{Sinput}
\begin{Soutput}
           rating complaints privileges learning raises critical advance
rating       1.00       0.83       0.43     0.62   0.59     0.16    0.16
complaints   0.83       1.00       0.56     0.60   0.67     0.19    0.22
privileges   0.43       0.56       1.00     0.49   0.45     0.15    0.34
learning     0.62       0.60       0.49     1.00   0.64     0.12    0.53
raises       0.59       0.67       0.45     0.64   1.00     0.38    0.57
critical     0.16       0.19       0.15     0.12   0.38     1.00    0.28
advance      0.16       0.22       0.34     0.53   0.57     0.28    1.00
\end{Soutput}
\begin{Sinput}
symnum(Ca) # simple graphic
\end{Sinput}
\begin{Soutput}
           rt cm p l rs cr a
rating     1                
complaints +  1             
privileges .  .  1          
learning   ,  .  . 1        
raises     .  ,  . , 1      
critical             .  1   
advance          . . .     1
attr(,"legend")
[1] 0 ' ' 0.3 '.' 0.6 ',' 0.8 '+' 0.9 '*' 0.95 'B' 1
\end{Soutput}
\begin{Sinput}
heatmap(Ca, symm = TRUE, margins = c(6,6)) # with reorder()
\end{Sinput}


{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-49-1} 

}

\end{Schunk}

\chapter{Regression in R}


\section{Stetige Response - lineare Regression}

Die lineare Regression ist die einfachste Form der Regression. Wir k?nnen diese bei einer stetigen Response verwenden. Die Annahme hierbei ist, dass die Response von den Pr?diktoren wie folgt abh?ngt:

\begin{Schunk}
\begin{Sinput}
y ~ par1 * pred1 +  par2 * pred2 +  par3 * pred2^2 + ... + residual Error
\end{Sinput}
\end{Schunk}

Wobei die Parameter par1 ... par3 gesch?tzt werden und der Residuenfehler normalverteilt ist.

Werfen wir einen Blick auf einige Beispiele, mit den Daten von Montag. Wir sehen, dass es eine Korrelation zwischen Ozon und Temperatur gibt.

\begin{Schunk}
\begin{Sinput}
plot(airquality$Temp~airquality$Ozone)
\end{Sinput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-51-1} \end{Schunk}

Mit dem Befehl lm() k?nnen wir R versuchen lassen, eine bestm?glich passende Gerade zwischen den beiden Variablen zu finden.

\begin{Schunk}
\begin{Sinput}
fit = lm(airquality$Temp~airquality$Ozone)
\end{Sinput}
\end{Schunk}

Lassen Sie uns das Ergebnis zuerst visuell betrachten

\begin{Schunk}
\begin{Sinput}
plot(airquality$Ozone, airquality$Temp)
abline(fit, col = "blue")
\end{Sinput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-53-1} \end{Schunk}

Hier ist die Ausgabe im Detail

\begin{Schunk}
\begin{Sinput}
summary(fit)
\end{Sinput}
\begin{Soutput}

Call:
lm(formula = airquality$Temp ~ airquality$Ozone)

Residuals:
    Min      1Q  Median      3Q     Max 
-22.147  -4.858   1.828   4.342  12.328 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)      69.41072    1.02971   67.41   <2e-16 ***
airquality$Ozone  0.20081    0.01928   10.42   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.819 on 114 degrees of freedom
  (37 observations deleted due to missingness)
Multiple R-squared:  0.4877,	Adjusted R-squared:  0.4832 
F-statistic: 108.5 on 1 and 114 DF,  p-value: < 2.2e-16
\end{Soutput}
\end{Schunk}

In der Ausgabe sehen wir die Parameter f?r die Auswirkung von Ozon (genannt Regressionssteigung) und den Schnittpunkt.

R erkennt, dass die Linie gerade ist, weil wir dem Programm sagen, dass airquality$Temp~airquality$Ozone. Wir werden sp?ter sehen, wie wir das ?ndern k?nnen, wenn wir andere Funktionen anpassen wollen. 

\subsection{Residuenanalyse}

Mit plot(fit) erhalten wir die Residuen (die Abweichung von der Geraden). Wie bereits gesagt, geht die lineare Regression davon aus, dass diese normal verteilt sind, also sollten wir ?berpr?fen, ob dies wirklich der Fall ist.

\begin{Schunk}
\begin{Sinput}
par(mfrow=c(2,2))
plot(fit)
\end{Sinput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-55-1} \end{Schunk}

Hier sind die Residuen nicht wirklich homogen um den vorhergesagten Wert gestreut, was darauf hindeutet, dass das Modell nicht sehr gut passt. Dies h?tte man schon erahnen k?nnen, weil die Korrelation nicht sehr linear aussieht. Wir k?nnen einen quadratischen Term hinzuf?gen durch


\begin{Schunk}
\begin{Sinput}
fit2 = lm(airquality$Temp~airquality$Ozone + I(airquality$Ozone^2))
summary(fit2)
\end{Sinput}
\begin{Soutput}

Call:
lm(formula = airquality$Temp ~ airquality$Ozone + I(airquality$Ozone^2))

Residuals:
     Min       1Q   Median       3Q      Max 
-16.1553  -3.9374   0.9296   4.0393  12.9195 

Coefficients:
                        Estimate Std. Error t value Pr(>|t|)    
(Intercept)           63.8614538  1.3163562  48.514  < 2e-16 ***
airquality$Ozone       0.4896669  0.0524715   9.332 1.07e-15 ***
I(airquality$Ozone^2) -0.0023198  0.0003987  -5.818 5.64e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.008 on 113 degrees of freedom
  (37 observations deleted due to missingness)
Multiple R-squared:  0.6058,	Adjusted R-squared:  0.5988 
F-statistic: 86.83 on 2 and 113 DF,  p-value: < 2.2e-16
\end{Soutput}
\end{Schunk}

Die Residuen sehen jetzt besser aus

\begin{Schunk}
\begin{Sinput}
par(mfrow=c(2,2))
plot(fit2)
\end{Sinput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-57-1} \end{Schunk}

Plotten der Ergebnisse

\begin{Schunk}
\begin{Sinput}
plot(airquality$Ozone, airquality$Temp)
points(fit2$model[,2], predict(fit2), col = "blue")
\end{Sinput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-58-1} \end{Schunk}

\subsection{Kategorische Pr?diktoren}

Wenn wir kategoriale Variablen wie in diesem Datensatz haben

\begin{Schunk}
\begin{Sinput}
boxplot(PlantGrowth$weight~PlantGrowth$group, main = "growth of plants")
\end{Sinput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-59-1} \end{Schunk}

Funktioniert dies noch:

\begin{Schunk}
\begin{Sinput}
fit <- lm(weight~group, data = PlantGrowth)
summary(fit)
\end{Sinput}
\begin{Soutput}

Call:
lm(formula = weight ~ group, data = PlantGrowth)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.0710 -0.4180 -0.0060  0.2627  1.3690 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   5.0320     0.1971  25.527   <2e-16 ***
grouptrt1    -0.3710     0.2788  -1.331   0.1944    
grouptrt2     0.4940     0.2788   1.772   0.0877 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.6234 on 27 degrees of freedom
Multiple R-squared:  0.2641,	Adjusted R-squared:  0.2096 
F-statistic: 4.846 on 2 and 27 DF,  p-value: 0.01591
\end{Soutput}
\end{Schunk}

Eine Sache, die viele Menschen jetzt verwirrt, ist, dass wir zwei Parameter-Sch?tzungen f?r die eine Pr?diktor-Variable haben. Der Grund daf?r ist, dass es 3 Gruppen in der Datenmenge gibt. Die erste Gruppe wird in diesem Fall automatisch als Referenz gesetzt, und f?r die anderen Gruppen werden Pr?diktoren gesch?tzt. Die p-Werte f?r diese Pr?diktoren sind also gegen die Referenz (wenn ich Pr?diktor trt1 herausnehme, erh?lt er den Wert von ctrl). Daher h?ngen diese p-Werte f?r kategoriale Variablen von der Reihenfolge der Variablen ab (Man kann die Reihenfolge von trt1 als Referenz ?ndern.)


\subsection{ANOVA}

Eine Frage, die oft in diesem Zusammenhang auftaucht, ist: Gibt es ?berhaupt Unterschiede zwischen den Gruppen? Die Regression zeigt uns nur, ob es einen signifikanten Unterschied zwischen dem ersten Faktor und den zwei anderen gibt. Wenn wir auf allgemeine Differenzen testen wollen, k?nnen wir eine ANOVA des angepassten Objekts machen

\begin{Schunk}
\begin{Sinput}
aovresult <- aov(fit)
summary(aovresult)
\end{Sinput}
\begin{Soutput}
            Df Sum Sq Mean Sq F value Pr(>F)  
group        2  3.766  1.8832   4.846 0.0159 *
Residuals   27 10.492  0.3886                 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{Soutput}
\end{Schunk}

Beachte, dass wir jetzt Signifikanz f?r einen allgemeinen Unterschied erhalten, obwohl wir keine Signifikanz in der Regression zuvor hatten.

Wir k?nnen nun sogenannte Post-hoc-Tests verwenden, um herauszufinden, welche Unterschiede signifikant sind.

Weitere Beispiele mit weiteren Faktoren finden man \href{http://www.statmethods.net/stats/anova.html}{hier} 


Anmerkung: aov ist f?r ausgeglichene Versuchsanordnungen ausgelegt, und die Ergebnisse k?nnen schwer ohne Abgleich interpretiert werden: Achte darauf, dass fehlende Werte in der Response wahrscheinlich den Ausgleich kosten. Wenn es zwei oder mehr Fehler in den Stichprobenschichten gibt, sind die verwendeten Methoden ohne Ausgleich statistisch ineffizient, und es kann vorteilhaft sein lme in Paket nlme zu verwenden.

\subsection{T-Test}

Eine einfache Option f?r das Testen von nur zwei Gruppen gegeneinander ist der t-Test. Er nimmt eine normale Verteilung innerhalb der Gruppen an. Wir k?nnen dies verwenden, um post-hoc-Tests f?r das obige Beispiel durchzuf?hren:

\begin{Schunk}
\begin{Sinput}
attach(PlantGrowth)
t.test(weight[group=='ctrl'], weight[group=="trt1"])
\end{Sinput}
\begin{Soutput}

	Welch Two Sample t-test

data:  weight[group == "ctrl"] and weight[group == "trt1"]
t = 1.1913, df = 16.524, p-value = 0.2504
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.2875162  1.0295162
sample estimates:
mean of x mean of y 
    5.032     4.661 
\end{Soutput}
\end{Schunk}

Testen gegen Gruppe 2

\begin{Schunk}
\begin{Sinput}
t.test(weight[group=='ctrl'], weight[group=="trt2"])
\end{Sinput}
\begin{Soutput}

	Welch Two Sample t-test

data:  weight[group == "ctrl"] and weight[group == "trt2"]
t = -2.134, df = 16.786, p-value = 0.0479
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.98287213 -0.00512787
sample estimates:
mean of x mean of y 
    5.032     5.526 
\end{Soutput}
\begin{Sinput}
detach(PlantGrowth)
\end{Sinput}
\end{Schunk}

Aber wenn wir wirklich beide Tests ausgef?hrt h?tten, m?ssten wir f?r multiple Tests korrigieren

\begin{Schunk}
\begin{Sinput}
p.adjust(c(0.2504, 0.0479), method = "holm")
\end{Sinput}
\begin{Soutput}
[1] 0.2504 0.0958
\end{Soutput}
\end{Schunk}

Wie funktioniert das? Schreibe ?p.adjust in die Konsole. Lese auch \href{das hier}{http://webdev.cas.msu.edu/cas992/weeks/week10.html}

\section{Allgemeine lineare Modell-Rahmenbedingung}

Das GML ist eine Verallgemeinerung von linearen Modellen (lm) zu anderen Response-Typen. Wir k?nnten ein Modell erzeugen, das zu lm() identisch ist durch glm(formula, family = gaussian(link = "identity")), aber mit dem Vorteil, dass glm mehr Optionen hat; darunter die folgenden Vorgaben

\begin{Schunk}
\begin{Sinput}
binomial(link = "logit")
gaussian(link = "identity")
Gamma(link = "inverse")
inverse.gaussian(link = "1/mu^2")
poisson(link = "log")
quasi(link = "identity", variance = "constant")
quasibinomial(link = "logit")
quasipoisson(link = "log")
\end{Sinput}
\end{Schunk}

Aber Schritt f?r Schritt ... schauen wir uns ein Beispiel f?r binomische Daten an


\section{0/1 Response - die logistische Regression}

\begin{Schunk}
\begin{Sinput}
library(effects) 
\end{Sinput}
\begin{Soutput}
Error in library(effects): there is no package called 'effects'
\end{Soutput}
\begin{Sinput}
data(TitanicSurvival)
\end{Sinput}
\begin{Soutput}
Warning in data(TitanicSurvival): data set 'TitanicSurvival' not found
\end{Soutput}
\begin{Sinput}
head(TitanicSurvival)
\end{Sinput}
\begin{Soutput}
Error in head(TitanicSurvival): Objekt 'TitanicSurvival' nicht gefunden
\end{Soutput}
\begin{Sinput}
str(TitanicSurvival)
\end{Sinput}
\begin{Soutput}
Error in str(TitanicSurvival): Objekt 'TitanicSurvival' nicht gefunden
\end{Soutput}
\begin{Sinput}
attach(TitanicSurvival)
\end{Sinput}
\begin{Soutput}
Error in attach(TitanicSurvival): Objekt 'TitanicSurvival' nicht gefunden
\end{Soutput}
\end{Schunk}

Veranschaulichen wir uns dies. Informationen zur Visualisierung von Assoziationen finden Sie unter http://www.statmethods.net/advgraphs/mosaic.html

Wir benutzen das Mosaikplot. M?glicherweise muss man zuvor das Paket installieren: install.packages ("vcd")

\begin{Schunk}
\begin{Sinput}
library(vcd)
\end{Sinput}
\begin{Soutput}
Error in library(vcd): there is no package called 'vcd'
\end{Soutput}
\begin{Sinput}
mosaic(~ sex + passengerClass + survived, shade=TRUE, legend=TRUE) 
\end{Sinput}
\begin{Soutput}
Error in eval(expr, envir, enclos): konnte Funktion "mosaic" nicht finden
\end{Soutput}
\begin{Sinput}
surv <- as.numeric(survived)-1 # glm requires 0 / 1 not true false
\end{Sinput}
\begin{Soutput}
Error in eval(expr, envir, enclos): Objekt 'survived' nicht gefunden
\end{Soutput}
\end{Schunk}

Wie analysieren wir diese Daten? Die Response ist eindeutig nicht normal, jedoch 1/0. Das glm ist im Grunde das gleiche wie lm (), nur dass wir die Familie angeben.

Wir werden zuerst testen, ob das ?berleben mit dem Alter korreliert

\begin{Schunk}
\begin{Sinput}
fmt <- glm(surv ~ age, family=binomial)
\end{Sinput}
\begin{Soutput}
Error in eval(expr, envir, enclos): Objekt 'surv' nicht gefunden
\end{Soutput}
\begin{Sinput}
summary(fmt)
\end{Sinput}
\begin{Soutput}
Error in summary(fmt): Objekt 'fmt' nicht gefunden
\end{Soutput}
\end{Schunk}

Ergebnis geplottet

\begin{Schunk}
\begin{Sinput}
plot(surv ~ age, main="only age term")
\end{Sinput}
\begin{Soutput}
Error in eval(expr, envir, enclos): Objekt 'surv' nicht gefunden
\end{Soutput}
\begin{Sinput}
newage <- seq(min(age, na.rm=T), max(age, na.rm=T), len=100)
\end{Sinput}
\begin{Soutput}
Error in seq(min(age, na.rm = T), max(age, na.rm = T), len = 100): Objekt 'age' nicht gefunden
\end{Soutput}
\begin{Sinput}
preds <- predict(fmt, newdata=data.frame("age"=newage), se.fit=T)
\end{Sinput}
\begin{Soutput}
Error in predict(fmt, newdata = data.frame(age = newage), se.fit = T): Objekt 'fmt' nicht gefunden
\end{Soutput}
\begin{Sinput}
lines(newage, plogis(preds$fit), col="purple", lwd=3)
\end{Sinput}
\begin{Soutput}
Error in lines(newage, plogis(preds$fit), col = "purple", lwd = 3): Objekt 'newage' nicht gefunden
\end{Soutput}
\begin{Sinput}
lines(newage, plogis(preds$fit-2*preds$se.fit), col="purple", lwd=3, lty=2)
\end{Sinput}
\begin{Soutput}
Error in lines(newage, plogis(preds$fit - 2 * preds$se.fit), col = "purple", : Objekt 'newage' nicht gefunden
\end{Soutput}
\begin{Sinput}
lines(newage, plogis(preds$fit+2*preds$se.fit), col="purple", lwd=3, lty=2)
\end{Sinput}
\begin{Soutput}
Error in lines(newage, plogis(preds$fit + 2 * preds$se.fit), col = "purple", : Objekt 'newage' nicht gefunden
\end{Soutput}
\end{Schunk}

Nun setzen wir alle relevanten Variablen ein in:

\begin{Schunk}
\begin{Sinput}
surv <- as.numeric(survived)-1 # glm requires 0 / 1 not true false
\end{Sinput}
\begin{Soutput}
Error in eval(expr, envir, enclos): Objekt 'survived' nicht gefunden
\end{Soutput}
\begin{Sinput}
fmt <- glm(surv ~ age  + sex + passengerClass, family=binomial)
\end{Sinput}
\begin{Soutput}
Error in eval(expr, envir, enclos): Objekt 'surv' nicht gefunden
\end{Soutput}
\begin{Sinput}
summary(fmt)
\end{Sinput}
\begin{Soutput}
Error in summary(fmt): Objekt 'fmt' nicht gefunden
\end{Soutput}
\end{Schunk}

\subsection{ANOVA f?r GLM}

Wenn eine ANOVA erw?nscht ist

\begin{Schunk}
\begin{Sinput}
library(car)
\end{Sinput}
\begin{Soutput}
Error in library(car): there is no package called 'car'
\end{Soutput}
\begin{Sinput}
Anova(fmt)
\end{Sinput}
\begin{Soutput}
Error in eval(expr, envir, enclos): konnte Funktion "Anova" nicht finden
\end{Soutput}
\begin{Sinput}
detach(TitanicSurvival)
\end{Sinput}
\begin{Soutput}
Error in detach(TitanicSurvival): invalid 'name' argument
\end{Soutput}
\end{Schunk}

\section{Z?hldaten - Poisson's Regression}

F?r Z?hldaten verwenden wir den GLM mit der Poisson'schen-Fehlerverteilung. Hier sind einige Beobachtungen der Verteilung von Futterst?cke an junge V?gel und ihre wahrgenommene Attraktivit?t.

\begin{Schunk}
\begin{Sinput}
cfc <- data.frame(
  stuecke = c(3,6,8,4,2,7,6,8,10,3,5,7,6,7,5,6,7,11,8,11,13,11,7,7,6),
  attrakt = c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,4,4,4,4,4,5,5,5,5,5) 
)
attach(cfc)
plot(stuecke ~ attrakt)
\end{Sinput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-72-1} \end{Schunk}

So wird der Poisson angegeben

\begin{Schunk}
\begin{Sinput}
fm <- glm(stuecke ~ attrakt, family=poisson)
summary(fm)
\end{Sinput}
\begin{Soutput}

Call:
glm(formula = stuecke ~ attrakt, family = poisson)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.55377  -0.72834   0.03699   0.59093   1.54584  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  1.47459    0.19443   7.584 3.34e-14 ***
attrakt      0.14794    0.05437   2.721  0.00651 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 25.829  on 24  degrees of freedom
Residual deviance: 18.320  on 23  degrees of freedom
AIC: 115.42

Number of Fisher Scoring iterations: 4
\end{Soutput}
\end{Schunk}

Vorhersagen

\begin{Schunk}
\begin{Sinput}
newattrakt <- c(1,1.5,2,2.5,3,3.5,4,4.5,5)
preds <- predict(fm, newdata=data.frame("attrakt"=newattrakt))
plot(stuecke ~ attrakt)
lines(newattrakt, exp(preds), lwd=2, col="green")
\end{Sinput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-74-1} \end{Schunk}

Das gleiche mit 95\% Konfidenzinterval:

\begin{Schunk}
\begin{Sinput}
preds <- predict(fm, newdata=data.frame("attrakt"=newattrakt), se.fit=T)
str(preds)
\end{Sinput}
\begin{Soutput}
List of 3
 $ fit           : Named num [1:9] 1.62 1.7 1.77 1.84 1.92 ...
  ..- attr(*, "names")= chr [1:9] "1" "2" "3" "4" ...
 $ se.fit        : Named num [1:9] 0.1459 0.1235 0.1034 0.0872 0.0775 ...
  ..- attr(*, "names")= chr [1:9] "1" "2" "3" "4" ...
 $ residual.scale: num 1
\end{Soutput}
\begin{Sinput}
plot(stuecke ~ attrakt)
lines(newattrakt, exp(preds$fit), lwd=2, col="green")
lines(newattrakt, exp(preds$fit+2*preds$se.fit), lwd=2, col="green", lty=2)
lines(newattrakt, exp(preds$fit-2*preds$se.fit), lwd=2, col="green", lty=2)
\end{Sinput}

\includegraphics[width=\maxwidth]{figure/unnamed-chunk-75-1} \begin{Sinput}
detach(cfc)
\end{Sinput}
\end{Schunk}



\section{Multinomiale Daten - multinomiale Regression}

Wenn Sie mehrere Optionen f?r die Response haben (rot, gr?n, blau), passt dies zu einer multinomialen Regression. Dies ist nicht im Standard-GLM-Paket. Das Standardpaket dazu w?re mlogit. Ich gebe dazu unten ein Beispiel an. Das Problem mit mlogit ist, dass es Daten in einer bestimmten Weise erfordert, d.h. dass f?r jede Beobachtung jede Auswahl eine einzelne Zeile ist. Zus?tzlich gibt es eine Spalte, die sagt, welche Wahl getroffen wurde (ja / nein). Um mlogit verwenden zu k?nnen, m?ssen Sie die Daten in dieses Format umwandeln.

Wenn man die Daten nicht in diesem Format hat und nicht neu formatieren m?chte, ist eine weniger leistungsstarke, aber einfacher zu bedienende Alternative die multinomiale Funktion aus dem nnet-Paket. Im Folgenden finden Sie ein Beispiel f?r die Verwendung dieser Funktion oder \href{http://www.ats.ucla.edu/stat/stata/dae/mlogit.htm}{hier}.

\subsection{mlogit Beispiel}


\begin{Schunk}
\begin{Sinput}
library(mlogit)
\end{Sinput}
\begin{Soutput}
Error in library(mlogit): there is no package called 'mlogit'
\end{Soutput}
\begin{Sinput}
data("Fishing", package = "mlogit")
\end{Sinput}
\begin{Soutput}
Error in find.package(package, lib.loc, verbose = verbose): there is no package called 'mlogit'
\end{Soutput}
\begin{Sinput}
head(Fishing)
\end{Sinput}
\begin{Soutput}
Error in head(Fishing): Objekt 'Fishing' nicht gefunden
\end{Soutput}
\end{Schunk}

Die Daten, die wir verwenden, ist ein Datenframe mit folgendem Inhalt :

\begin{enumerate}
\setlength\itemsep{-0.5em}
\item price.beach -price for beach mode

\item price.pier -price for pier mode

\item price.boat -price for private boat mode

\item price.charter -price for charter boat mode

\item catch.beach -catch rate for beach mode

\item catch.pier -catch rate for pier mode

\item catch.boat -catch rate for private boat mode

\item catch.charter -catch rate for charter boat mode

\item income - monthly income

\item mode -recreation mode choice, one of : beach, pier, boat and charter

\end{enumerate}

Wir transformieren das in ein Objekt, mit dem mlogit arbeiten kann

\begin{Schunk}
\begin{Sinput}
Fish <- mlogit.data(Fishing, varying = c(2:9), shape = "wide", choice = "mode")
\end{Sinput}
\begin{Soutput}
Error in eval(expr, envir, enclos): konnte Funktion "mlogit.data" nicht finden
\end{Soutput}
\end{Schunk}

Variation zeigt dem Modell an, dass es sich um Variablen handelt, die f?r die alternativen Outputs der Response spezifisch sind, z.B. der Preis des Bootes; w?hrend Variablen, die nicht variieren, unabh?ngig vom Output sind, z.B. Einkommen.

\begin{Schunk}
\begin{Sinput}
## a pure "conditional" model
summary(mlogit(mode ~ price + catch, data = Fish))
\end{Sinput}
\begin{Soutput}
Error in summary(mlogit(mode ~ price + catch, data = Fish)): konnte Funktion "mlogit" nicht finden
\end{Soutput}
\end{Schunk}

F?r jeden Outcome passt die Erh?hung der "choice" zu "price" und "catch". Daher erhalten wir die Schnittpunkte f?r jeden Outcome und ein Parameter pro Variable, was die Auswirkung von "price" / "choice" auf die Wahrscheinlichkeit ist, eines der 4 Ergebnisse zu w?hlen.

Wenn wir die Variable "income" korrelieren, ist dies anders. Das Einkommen ist nicht spezifisch f?r "choice" (nicht als variabel ausgew?hlt, als wir die Daten eingelesen haben). In diesem Fall fragen wir uns, wie sich "choice" ver?ndert, wenn wir Menschen mit unterschiedlichen Einkommen haben. Daher erhalten wir einen Intervallwert pro Parameter und eine Sch?tzung, ob diese Wahl durch eine Erh?hung des Einkommens, bezogen auf die Grundlinie (Pier), beeinflusst wird.

\begin{Schunk}
\begin{Sinput}
## a pure "multinomial model"
summary(mlogit(mode ~ 0 | income, data = Fish))
\end{Sinput}
\begin{Soutput}
Error in summary(mlogit(mode ~ 0 | income, data = Fish)): konnte Funktion "mlogit" nicht finden
\end{Soutput}
\end{Schunk}

Wenn wir die Parameterwerte interpretieren wollen, m?ssen wir die Response mit der relativ komplizierten Linkfunktion der multinomialen logistischen Regression zur?ck transformieren, siehe \href{http://en.wikipedia.org/wiki/Multinomial_logistic_regression}{hier}. Mehr Beispiele \href{http://www.inside-r.org/packages/cran/mlogit/docs/suml}{hier} und ein mlogit Tutorial findet man \href{http://cran.r-project.org/web/packages/mlogit/vignettes/Exercises.pdf}{hier}.

\subsection{mlogit Beispiel}

\begin{Schunk}
\begin{Sinput}
require(nnet)
\end{Sinput}
\end{Schunk}

Wir verwenden die urspr?nglichen fishing- Daten (ohne Umformung), wie f?r das mlogit Beispiel siehe oben.
Und auch die gleiche Modellstruktur

\begin{Schunk}
\begin{Sinput}
## a pure "conditional" model
summary(multinom(mode ~ price.beach + price.pier + price.boat + price.charter + 
                   catch.beach + catch.pier + catch.boat + catch.charter, data = Fishing))
\end{Sinput}
\begin{Soutput}
Error in is.data.frame(data): Objekt 'Fishing' nicht gefunden
\end{Soutput}
\end{Schunk}
\end{appendices}


 
\end{document}
